{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, json, csv, requests, time, glob, tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_one_new(html, url):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    json_data = json.loads(soup.find_all(\"script\", type=\"application/ld+json\")[-1].text)\n",
    "\n",
    "    # title, date, genre, keyword\n",
    "    title = json_data.get('headline', soup.find('span', class_='contentTitle').text)\n",
    "    date = json_data.get('datePublished', re.search(r'datetime:.*?(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2})', str(html)).group(1))\n",
    "    date_m = json_data.get('dateModified', '')\n",
    "    genre = json_data.get('genre', [])\n",
    "    if genre == []:\n",
    "        genre = [k for k in soup.find('meta', attrs={'name':'keywords'}).get('content').split(',') if k not in ['NHK','ニュース', 'NHK NEWS WEB']]\n",
    "    keywords = json_data.get('keywords', [])\n",
    "    \n",
    "    # article: news_textbody > news_textmore > news_add (paragraph titles are h3)\n",
    "    article = soup.find('div', id=\"news_textbody\").text\n",
    "    if soup.find_all('div', id=\"news_textmore\") != []:\n",
    "        for textmore in soup.find_all('div', id=\"news_textmore\"):\n",
    "            article += ('\\n' + textmore.text)\n",
    "    if soup.find_all('div', class_=\"news_add\") != []:\n",
    "        for newsadd in soup.find_all('div', class_=\"news_add\"):\n",
    "            if newsadd.h3 != None:\n",
    "                newsadd.h3.extract()\n",
    "            article += ('\\n' + newsadd.text)\n",
    "            \n",
    "    return {\n",
    "        'id':url.split('/')[-1].split('.html')[0],\n",
    "        'title':title.strip(),\n",
    "        'article':article.strip(),\n",
    "        'genre':genre,\n",
    "        'keywords':keywords,\n",
    "        'url':url,\n",
    "        'datePublished':date,\n",
    "        'dateModified':date_m\n",
    "    }\n",
    "\n",
    "# for old web normal\n",
    "def make_datetime_normal_old(hmd, time):\n",
    "    year, month, day = hmd[:4], hmd[4:6], hmd[6:]\n",
    "    hour, minute = time.split('時')\n",
    "    minute = minute.strip('分')\n",
    "    if len(hour) == 1:\n",
    "        hour = '0' + hour\n",
    "    if len(minute) == 1:\n",
    "        minute = '0' + minute\n",
    "    return f\"{year}-{month}-{day}T{hour}:{minute}\"\n",
    "\n",
    "def scrape_one_old(html, url):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # title, date, genre, keyword\n",
    "    title = soup.find('span', class_=\"contentTitle\").text.strip()\n",
    "    hmd_ = url.split('/')[-2]\n",
    "    time_ = soup.find('span', id=\"news_time\").text\n",
    "    date = make_datetime_normal_old(hmd_, time_)\n",
    "    genre = [k for k in soup.find('meta', attrs={'name':'keywords'}).get('content').split(',') if k not in ['NHK','ニュース', 'NHK NEWS WEB','ＮＨＫ','ＮＨＫニュース','']]\n",
    "    \n",
    "    # article: news_textbody > news_textmore > news_add (paragraph titles are h3)\n",
    "    article = soup.find(['div','p'], id=\"news_textbody\").text\n",
    "    if soup.find_all(['div','p'], id=\"news_textmore\") != []:\n",
    "        for textmore in soup.find_all(['div','p'], id=\"news_textmore\"):\n",
    "            article += ('\\n' + textmore.text)\n",
    "    if soup.find_all(['div','p'], class_=\"news_add\") != []:\n",
    "        for newsadd in soup.find_all(['div','p'], class_=\"news_add\"):\n",
    "            if newsadd.h3 != None:\n",
    "                newsadd.h3.extract()\n",
    "            article += ('\\n' + newsadd.text)\n",
    "            \n",
    "    return {\n",
    "        'id':url.split('/')[-1].split('.html')[0],\n",
    "        'title':title.strip(),\n",
    "        'article':article.strip(),\n",
    "        'genre':genre,\n",
    "        'keywords':[],\n",
    "        'url':url,\n",
    "        'datePublished':date,\n",
    "        'dateModified':\"\"\n",
    "    }\n",
    "\n",
    "def get_archiveurl(url, sleeptime=5):\n",
    "    driver.get(url)\n",
    "    time.sleep(sleeptime)\n",
    "    html = str(driver.page_source.encode('utf-8'))\n",
    "    snap = re.search(r'(times between|1 time|times).*?<a href=\"(.+?)\">', html)\n",
    "    #if snap == None:\n",
    "        #return None\n",
    "    archiveurl = 'https://web.archive.org' + snap.group(2)\n",
    "    return archiveurl\n",
    "\n",
    "def js(dic, year):\n",
    "    with open(f'nhkweb{year}.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    with open(f'nhkweb{year}.json', 'w', encoding='utf-8') as f:\n",
    "        if dic['id'] not in [x['id'] for x in data]:\n",
    "            data.append(dic)\n",
    "        else:\n",
    "            for i, d in enumerate(data):\n",
    "                if dic['id'] == d['id']:\n",
    "                    data[i] = dic\n",
    "        data = sorted(data, key=lambda x:x['id'])\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def geturl(year=2019):\n",
    "    idnormal = pd.read_json(f'nhkweb{year}.json', encoding='utf-8')['id'].tolist()\n",
    "    existurl = pd.read_csv('linknormal.txt', encoding='utf-8', header=None)[0].tolist()\n",
    "    nolink = pd.read_csv('nolinknormal.txt', encoding='utf-8', header=None)[0].tolist()\n",
    "    urls = set(existurl) - set(nolink)\n",
    "    return sorted([url for url in urls if (url.split('.html')[0].split('/')[-1] not in idnormal) and f'html/{year}' in url])\n",
    "\n",
    "def checkwrongid(): # check wrong ID in newswebeasy\n",
    "    df = pd.read_json('nhkwebeasy.json', encoding='utf-8')\n",
    "    print(len(df))\n",
    "    df['normalID'] = df['url_normal'].apply(lambda x:x.split('/')[-1].strip('.html'))\n",
    "    return df[df['id'] != df['normalID']]['id'].tolist()\n",
    "\n",
    "def wrongscrape():\n",
    "    wrongids = wrongid()\n",
    "    existurl = pd.read_csv('linknormal.txt', encoding='utf-8', header=None)[0].tolist()[::-1]\n",
    "    for ID in wrongids:\n",
    "        for url in existurl:\n",
    "            if ID in url:\n",
    "                print(url.split('/*/')[-1])\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>genre</th>\n",
       "      <th>keywords</th>\n",
       "      <th>url</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>dateModified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k10010000061000</td>\n",
       "      <td>ノルディック複合団体ラージヒル 日本６位</td>\n",
       "      <td>スウェーデンで行われているノルディックスキーの世界選手権は２８日、ノルディック複合の団体ラー...</td>\n",
       "      <td>[スポーツ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp:80/news/html/20150301/k1...</td>\n",
       "      <td>2015-03-01T03:03</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k10010000071000</td>\n",
       "      <td>びわ湖毎日マラソン きょう開催</td>\n",
       "      <td>ことし北京で行われる陸上の世界選手権の代表選考レースを兼ねた「びわ湖毎日マラソン」が１日、行...</td>\n",
       "      <td>[スポーツ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp:80/news/html/20150301/k1...</td>\n",
       "      <td>2015-03-01T04:15</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k10010000091000</td>\n",
       "      <td>ジャンプ男子団体ラージヒル 日本は４位</td>\n",
       "      <td>スウェーデンで行われているノルディックスキーの世界選手権は２８日、ジャンプの男子団体ラージヒ...</td>\n",
       "      <td>[スポーツ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp:80/news/html/20150301/k1...</td>\n",
       "      <td>2015-03-01T04:04</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k10010000111000</td>\n",
       "      <td>過激派組織ＩＳ より過激なグループが主導権か</td>\n",
       "      <td>過激派組織ＩＳ＝イスラミックステートがフリージャーナリストの後藤健二さんを殺害したとする映像...</td>\n",
       "      <td>[国際]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp/news/html/20150301/k1001...</td>\n",
       "      <td>2015-03-01T06:24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k10010000121000</td>\n",
       "      <td>インドで日本の新幹線導入目指しＰＲ</td>\n",
       "      <td>インドで初めてとなる高速鉄道に日本の新幹線の技術やノウハウを導入してもらおうと、首都ニューデ...</td>\n",
       "      <td>[国際]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp:80/news/html/20150301/k1...</td>\n",
       "      <td>2015-03-01T04:23</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>k10015826111000</td>\n",
       "      <td>英ウィリアム王子 首相と福島視察</td>\n",
       "      <td>安倍総理大臣は日本を訪れているイギリス王室のウィリアム王子と共に福島県を訪れ、原発事故の影響...</td>\n",
       "      <td>[社会, ウィリアム, イギリス王室, 王子]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp/news/html/20150228/k1001...</td>\n",
       "      <td>2015-02-28T19:15</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>k10015826211000</td>\n",
       "      <td>着床前スクリーニング 研究計画を公表</td>\n",
       "      <td>体外受精をしても妊娠できなかったり流産を繰り返したりする女性を対象に、受精卵のすべての染色体...</td>\n",
       "      <td>[科学・医療]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp/news/html/20150228/k1001...</td>\n",
       "      <td>2015-02-28T19:26</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5654</th>\n",
       "      <td>k10015827381000</td>\n",
       "      <td>転売巡る指摘 北朝鮮メディアが非難</td>\n",
       "      <td>北朝鮮の国営メディアは、朝鮮総連＝在日本朝鮮人総連合会の中央本部の土地と建物の転売を巡り、日...</td>\n",
       "      <td>[国際]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp/news/html/20150228/k1001...</td>\n",
       "      <td>2015-02-28T22:30</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>k10015827681000</td>\n",
       "      <td>捜索に抵抗し逃走の男 警察に出頭し逮捕</td>\n",
       "      <td>今月６日、山口県下関市で麻薬特例法違反の疑いで警察の捜索を受けた男が刃物で抵抗して逃走した事...</td>\n",
       "      <td>[社会]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp/news/html/20150228/k1001...</td>\n",
       "      <td>2015-02-28T23:16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5656</th>\n",
       "      <td>k10015827781000</td>\n",
       "      <td>インド 予算案提出 成長実現の方針強調</td>\n",
       "      <td>インド政府は来年度の予算案を議会に提出し、インフラ整備への支出を大幅に増やすとともに、法人税...</td>\n",
       "      <td>[経済]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://www3.nhk.or.jp/news/html/20150228/k1001...</td>\n",
       "      <td>2015-02-28T23:44</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5657 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                   title  \\\n",
       "0     k10010000061000    ノルディック複合団体ラージヒル 日本６位   \n",
       "1     k10010000071000         びわ湖毎日マラソン きょう開催   \n",
       "2     k10010000091000     ジャンプ男子団体ラージヒル 日本は４位   \n",
       "3     k10010000111000  過激派組織ＩＳ より過激なグループが主導権か   \n",
       "4     k10010000121000       インドで日本の新幹線導入目指しＰＲ   \n",
       "...               ...                     ...   \n",
       "5652  k10015826111000        英ウィリアム王子 首相と福島視察   \n",
       "5653  k10015826211000      着床前スクリーニング 研究計画を公表   \n",
       "5654  k10015827381000       転売巡る指摘 北朝鮮メディアが非難   \n",
       "5655  k10015827681000     捜索に抵抗し逃走の男 警察に出頭し逮捕   \n",
       "5656  k10015827781000     インド 予算案提出 成長実現の方針強調   \n",
       "\n",
       "                                                article  \\\n",
       "0     スウェーデンで行われているノルディックスキーの世界選手権は２８日、ノルディック複合の団体ラー...   \n",
       "1     ことし北京で行われる陸上の世界選手権の代表選考レースを兼ねた「びわ湖毎日マラソン」が１日、行...   \n",
       "2     スウェーデンで行われているノルディックスキーの世界選手権は２８日、ジャンプの男子団体ラージヒ...   \n",
       "3     過激派組織ＩＳ＝イスラミックステートがフリージャーナリストの後藤健二さんを殺害したとする映像...   \n",
       "4     インドで初めてとなる高速鉄道に日本の新幹線の技術やノウハウを導入してもらおうと、首都ニューデ...   \n",
       "...                                                 ...   \n",
       "5652  安倍総理大臣は日本を訪れているイギリス王室のウィリアム王子と共に福島県を訪れ、原発事故の影響...   \n",
       "5653  体外受精をしても妊娠できなかったり流産を繰り返したりする女性を対象に、受精卵のすべての染色体...   \n",
       "5654  北朝鮮の国営メディアは、朝鮮総連＝在日本朝鮮人総連合会の中央本部の土地と建物の転売を巡り、日...   \n",
       "5655  今月６日、山口県下関市で麻薬特例法違反の疑いで警察の捜索を受けた男が刃物で抵抗して逃走した事...   \n",
       "5656  インド政府は来年度の予算案を議会に提出し、インフラ整備への支出を大幅に増やすとともに、法人税...   \n",
       "\n",
       "                        genre keywords  \\\n",
       "0                      [スポーツ]       []   \n",
       "1                      [スポーツ]       []   \n",
       "2                      [スポーツ]       []   \n",
       "3                        [国際]       []   \n",
       "4                        [国際]       []   \n",
       "...                       ...      ...   \n",
       "5652  [社会, ウィリアム, イギリス王室, 王子]       []   \n",
       "5653                  [科学・医療]       []   \n",
       "5654                     [国際]       []   \n",
       "5655                     [社会]       []   \n",
       "5656                     [経済]       []   \n",
       "\n",
       "                                                    url     datePublished  \\\n",
       "0     http://www3.nhk.or.jp:80/news/html/20150301/k1...  2015-03-01T03:03   \n",
       "1     http://www3.nhk.or.jp:80/news/html/20150301/k1...  2015-03-01T04:15   \n",
       "2     http://www3.nhk.or.jp:80/news/html/20150301/k1...  2015-03-01T04:04   \n",
       "3     http://www3.nhk.or.jp/news/html/20150301/k1001...  2015-03-01T06:24   \n",
       "4     http://www3.nhk.or.jp:80/news/html/20150301/k1...  2015-03-01T04:23   \n",
       "...                                                 ...               ...   \n",
       "5652  http://www3.nhk.or.jp/news/html/20150228/k1001...  2015-02-28T19:15   \n",
       "5653  http://www3.nhk.or.jp/news/html/20150228/k1001...  2015-02-28T19:26   \n",
       "5654  http://www3.nhk.or.jp/news/html/20150228/k1001...  2015-02-28T22:30   \n",
       "5655  http://www3.nhk.or.jp/news/html/20150228/k1001...  2015-02-28T23:16   \n",
       "5656  http://www3.nhk.or.jp/news/html/20150228/k1001...  2015-02-28T23:44   \n",
       "\n",
       "     dateModified  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  \n",
       "...           ...  \n",
       "5652               \n",
       "5653               \n",
       "5654               \n",
       "5655               \n",
       "5656               \n",
       "\n",
       "[5657 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('nhkweb2015.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "#options.headless = True\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-90b9c5073c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_one_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e43317fa45b8>\u001b[0m in \u001b[0;36mscrape_one_new\u001b[0;34m(html, url)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# title, date, genre, keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'headline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'contentTitle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datePublished'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'datetime:.*?(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2})'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-90b9c5073c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_one_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_one_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mjs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mid_exist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e43317fa45b8>\u001b[0m in \u001b[0;36mscrape_one_old\u001b[0;34m(html, url)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# title, date, genre, keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"contentTitle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mhmd_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mtime_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"news_time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "year = 2015\n",
    "urls = pd.read_csv(f'linknormal.txt', header=None)\n",
    "urls = sorted(urls[urls[0].str.contains(f'html/{year}')][0].tolist(), reverse=True)\n",
    "id_exist = set(pd.read_json(f'nhkweb{year}.json')['id'].tolist())\n",
    "\n",
    "for url in urls:\n",
    "    # check URL\n",
    "    ID = url.split('.html')[0].split('/')[-1]\n",
    "    if ID in id_exist:\n",
    "        continue\n",
    "\n",
    "    # get archive URL\n",
    "    archiveurl = get_archiveurl(url)\n",
    "\n",
    "    # request\n",
    "    html = None\n",
    "    response = requests.get(archiveurl)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "    elif response.status_code == 504:\n",
    "        response = requests.get(archiveurl)\n",
    "        if response.status_code == 504:\n",
    "            continue\n",
    "        html = response.text\n",
    "    if html == None:\n",
    "        continue\n",
    "    time.sleep(4)\n",
    "\n",
    "    # scrape\n",
    "    url_true = 'htt' + url.split('/htt')[-1]\n",
    "\n",
    "    try:\n",
    "        dic = scrape_one_new(html, url_true)\n",
    "    except:\n",
    "        dic = scrape_one_old(html, url_true)\n",
    "    js(dic, year)\n",
    "    id_exist.add(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'k10010627901000',\n",
       " 'title': '台風５号 北日本～東北の太平洋側 暴風・高波に警戒',\n",
       " 'article': '台風５号は日本の東の海上を北上していて、気象庁は北日本から東北にかけての太平洋側を中心に暴風や高波に警戒するよう呼びかけています。\\n気象庁の観測によりますと、台風５号は９日午前６時には、仙台市の東２７０キロの海上を１時間に２５キロの速さで北へ進んでいます。中心の気圧は９８０ヘクトパスカル、最大風速は３０メートル、最大瞬間風速は４０メートルで中心の東側２８０キロ以内と西側１７０キロ以内では風速２５メートル以上の暴風が吹いています。台風はこのあとも北上を続け、９日夜には北海道の東の海上に進み、１０日の朝には千島の近海で温帯低気圧に変わる見込みです。東北の太平洋側では、海はうねりを伴って大しけとなっていて、１０日は北海道の太平洋側でも大しけとなる見込みです。また、北海道の太平洋側では９日夜にかけて非常に強い風が吹き、最大風速は２０メートル、最大瞬間風速は３０メートルに達すると予想されています。気象庁は北日本から東北にかけての太平洋側を中心に、暴風や高波に警戒するよう呼びかけています。',\n",
       " 'genre': ['気象', '災害'],\n",
       " 'keywords': [],\n",
       " 'url': 'http://www3.nhk.or.jp/news/html/20160809/k10010627901000.html',\n",
       " 'datePublished': '2016-08-09T06:29',\n",
       " 'dateModified': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_true = 'htt' + driver.current_url.split('/htt')[-1]\n",
    "html = driver.page_source.encode('utf-8')\n",
    "try:\n",
    "    dic = scrape_one_new(html, url_true)\n",
    "except:\n",
    "    dic = scrape_one_old(html, url_true)\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "js(dic, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles:  10740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('国際', 4223),\n",
       " ('社会', 2827),\n",
       " ('政治', 1525),\n",
       " ('ビジネス', 1341),\n",
       " ('スポーツ', 943),\n",
       " ('気象・災害', 792),\n",
       " ('科学・文化', 783),\n",
       " ('暮らし', 519),\n",
       " ('地域', 423)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check category\n",
    "\n",
    "year = 2017\n",
    "\n",
    "with open(f'nhkweb{year}.json','r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "print('articles: ', len(data))\n",
    "genre = Counter()\n",
    "for dic in data:\n",
    "    for g in dic['genre']:\n",
    "        genre[g] += 1\n",
    "genre.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre <> keywords\n",
    "with open(f'nhkweb{year}.json','r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "category = ['社会', '国際', 'ビジネス', 'スポーツ', '政治', '科学・文化', '暮らし', '地域', '気象・災害']\n",
    "for i, dic in enumerate(data):\n",
    "    newgenre = []\n",
    "    newkey = []\n",
    "    for j in dic['genre']:\n",
    "        if j in category:\n",
    "            newgenre.append(j)\n",
    "        elif j == \"災害\" or j == \"気象\":\n",
    "            newgenre.append('気象・災害')\n",
    "        elif j == \"科学・医療\" or j == \"文化・エンタメ\" or j == \"科学\":\n",
    "            newgenre.append('科学・文化')\n",
    "        elif j == \"暮らし文化\":\n",
    "            newgenre.append('暮らし')\n",
    "            newgenre.append('科学・文化')\n",
    "        elif j == \"経済\":\n",
    "            newgenre.append('ビジネス')\n",
    "        else:\n",
    "            newkey.append(j)\n",
    "    for j in dic['keywords']:\n",
    "        if j in category:\n",
    "            newgenre.append(j)\n",
    "        elif j == \"科学・医療\" or j == \"文化・エンタメ\" or j == \"科学\":\n",
    "            newgenre.append('科学・文化')\n",
    "        elif j == \"暮らし文化\":\n",
    "            newgenre.append('暮らし')\n",
    "            newgenre.append('科学・文化')\n",
    "        elif j == \"災害\" or j == \"気象\":\n",
    "            newgenre.append('気象・災害')\n",
    "        else:\n",
    "            newkey.append(j)\n",
    "    data[i]['genre'] = list(set(newgenre))\n",
    "    data[i]['keywords'] = list(set(newkey))\n",
    "\n",
    "with open(f'nhkweb{year}.json','w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3444200851a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'nhkweb{year}.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1093\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m             )\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pd.read_json(f'nhkweb{year}.json').id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nhk thai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128206/',\n",
       " 'https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128207/',\n",
       " 'https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128208/',\n",
       " 'https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128209/',\n",
       " 'https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128210/',\n",
       " 'https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128211/',\n",
       " 'https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128212/',\n",
       " 'https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128213/',\n",
       " 'https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128214/',\n",
       " 'https://web.archive.org/web/2019*/https://www3.nhk.or.jp//nhkworld/th/news/128215/']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = pd.read_json('nhkthailink.json')[0].tolist()\n",
    "print(len(urls))\n",
    "urls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#options = Options()\n",
    "#options.headless = True\n",
    "#driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "def writejson(diclist):\n",
    "    with open ('nhk2.json', 'w', encoding='utf-8') as f:\n",
    "        with open ('nhk.json', 'r', encoding='utf-8') as g:\n",
    "            old_list = json.load(g)\n",
    "            for dic in diclist:\n",
    "                if dic not in old_list:\n",
    "                    old_list.append(dic)\n",
    "        old_list = sorted(old_list, key=lambda x: x['id'])\n",
    "        json.dump(old_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://web.archive.org/web/20190826060201/https://www3.nhk.or.jp/nhkworld/th/news/179442/\n",
      "https://web.archive.org/web/20190826060147/https://www3.nhk.or.jp/nhkworld/th/news/179603/\n",
      "https://web.archive.org/web/20190826060148/https://www3.nhk.or.jp/nhkworld/th/news/179604/\n",
      "https://web.archive.org/web/20190826060150/https://www3.nhk.or.jp/nhkworld/th/news/179605/\n",
      "https://web.archive.org/web/20190826060151/https://www3.nhk.or.jp/nhkworld/th/news/179606/\n",
      "https://web.archive.org/web/20190826060152/https://www3.nhk.or.jp/nhkworld/th/news/179607/\n",
      "https://web.archive.org/web/20190826060153/https://www3.nhk.or.jp/nhkworld/th/news/179608/\n",
      "https://web.archive.org/web/20190828081234/https://www3.nhk.or.jp/nhkworld/th/news/179784/\n",
      "https://web.archive.org/web/20190828081235/https://www3.nhk.or.jp/nhkworld/th/news/179785/\n",
      "https://web.archive.org/web/20190828081235/https://www3.nhk.or.jp/nhkworld/th/news/179786/\n",
      "https://web.archive.org/web/20190828081236/https://www3.nhk.or.jp/nhkworld/th/news/179787/\n",
      "https://web.archive.org/web/20190828081238/https://www3.nhk.or.jp/nhkworld/th/news/179788/\n",
      "https://web.archive.org/web/20190828081238/https://www3.nhk.or.jp/nhkworld/th/news/179789/\n",
      "https://web.archive.org/web/20190828081239/https://www3.nhk.or.jp/nhkworld/th/news/179790/\n",
      "https://web.archive.org/web/20190828081241/https://www3.nhk.or.jp/nhkworld/th/news/179791/\n",
      "https://web.archive.org/web/20190828081242/https://www3.nhk.or.jp/nhkworld/th/news/179792/\n",
      "https://web.archive.org/web/20190828081243/https://www3.nhk.or.jp/nhkworld/th/news/179793/\n",
      "https://web.archive.org/web/20190828081244/https://www3.nhk.or.jp/nhkworld/th/news/179794/\n",
      "https://web.archive.org/web/20190828081225/https://www3.nhk.or.jp/nhkworld/th/news/180040/\n",
      "https://web.archive.org/web/20190828081226/https://www3.nhk.or.jp/nhkworld/th/news/180041/\n",
      "https://web.archive.org/web/20190828081227/https://www3.nhk.or.jp/nhkworld/th/news/180042/\n",
      "https://web.archive.org/web/20190828081228/https://www3.nhk.or.jp/nhkworld/th/news/180043/\n",
      "https://web.archive.org/web/20190828081229/https://www3.nhk.or.jp/nhkworld/th/news/180044/\n",
      "https://web.archive.org/web/20190828081230/https://www3.nhk.or.jp/nhkworld/th/news/180045/\n",
      "https://web.archive.org/web/20190828081231/https://www3.nhk.or.jp/nhkworld/th/news/180046/\n",
      "https://web.archive.org/web/20190828081232/https://www3.nhk.or.jp/nhkworld/th/news/180047/\n",
      "https://web.archive.org/web/20190828081233/https://www3.nhk.or.jp/nhkworld/th/news/180048/\n",
      "https://web.archive.org/web/20190828081223/https://www3.nhk.or.jp/nhkworld/th/news/180070/\n",
      "https://web.archive.org/web/20190828081224/https://www3.nhk.or.jp/nhkworld/th/news/180071/\n",
      "https://web.archive.org/web/20190830083937/https://www3.nhk.or.jp/nhkworld/th/news/180306/\n",
      "https://web.archive.org/web/20190830083938/https://www3.nhk.or.jp/nhkworld/th/news/180307/\n",
      "https://web.archive.org/web/20190830083939/https://www3.nhk.or.jp/nhkworld/th/news/180308/\n",
      "https://web.archive.org/web/20190830083940/https://www3.nhk.or.jp/nhkworld/th/news/180309/\n",
      "https://web.archive.org/web/20190830083941/https://www3.nhk.or.jp/nhkworld/th/news/180310/\n",
      "https://web.archive.org/web/20190830083942/https://www3.nhk.or.jp/nhkworld/th/news/180311/\n",
      "https://web.archive.org/web/20190830083942/https://www3.nhk.or.jp/nhkworld/th/news/180312/\n",
      "https://web.archive.org/web/20190830083943/https://www3.nhk.or.jp/nhkworld/th/news/180313/\n",
      "https://web.archive.org/web/20190830083944/https://www3.nhk.or.jp/nhkworld/th/news/180314/\n",
      "https://web.archive.org/web/20190830083929/https://www3.nhk.or.jp/nhkworld/th/news/180515/\n",
      "https://web.archive.org/web/20190830083930/https://www3.nhk.or.jp/nhkworld/th/news/180516/\n",
      "https://web.archive.org/web/20190830083931/https://www3.nhk.or.jp/nhkworld/th/news/180517/\n",
      "https://web.archive.org/web/20190830083932/https://www3.nhk.or.jp/nhkworld/th/news/180518/\n",
      "https://web.archive.org/web/20190830083933/https://www3.nhk.or.jp/nhkworld/th/news/180519/\n",
      "https://web.archive.org/web/20190830083934/https://www3.nhk.or.jp/nhkworld/th/news/180520/\n",
      "https://web.archive.org/web/20190830083935/https://www3.nhk.or.jp/nhkworld/th/news/180521/\n",
      "https://web.archive.org/web/20190830083936/https://www3.nhk.or.jp/nhkworld/th/news/180522/\n"
     ]
    }
   ],
   "source": [
    "diclist = []\n",
    "with open ('nhk.json', 'r', encoding='utf-8') as g:\n",
    "    idlist = json.load(g)\n",
    "idlist = [x['id'] for x in idlist]\n",
    "\n",
    "for url in urls:\n",
    "    ID = url.split('/')[-2]\n",
    "    if ID in idlist:\n",
    "        continue\n",
    "    for i in range(5):\n",
    "        archiveurl = get_archiveurl(url, 5)\n",
    "        if 'nhkworld' in archiveurl:\n",
    "            break\n",
    "    print(archiveurl)\n",
    "    driver.get(archiveurl)\n",
    "    time.sleep(5)\n",
    "    html = driver.page_source.encode('utf-8')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    dic = {} \n",
    "    data = soup.find_all('script', type=\"application/ld+json\")[-1]\n",
    "    data = json.loads(data.text)\n",
    "    dic['headline'] = data['headline']\n",
    "    dic['article'] = data['articleBody']\n",
    "    dic['date'] = data['datePublished']\n",
    "    dic['url'] = url\n",
    "    dic['id'] = ID\n",
    "    diclist.append(dic)\n",
    "    \n",
    "writejson(diclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "writejson(diclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit72de44cd76184052b9457c2863c13ac2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
