{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bit72de44cd76184052b9457c2863c13ac2",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, json, csv, requests, time, glob, tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_one_new(html, url):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    json_data = json.loads(soup.find_all(\"script\", type=\"application/ld+json\")[-1].text)\n",
    "\n",
    "    # title, date, genre, keyword\n",
    "    title = json_data.get('headline', soup.find('span', class_='contentTitle').text)\n",
    "    date = json_data.get('datePublished', re.search(r'datetime:.*?(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2})', str(html)).group(1))\n",
    "    date_m = json_data.get('dateModified', '')\n",
    "    genre = json_data.get('genre', [])\n",
    "    if genre == []:\n",
    "        genre = [k for k in soup.find('meta', attrs={'name':'keywords'}).get('content').split(',') if k not in ['NHK','ニュース', 'NHK NEWS WEB']]\n",
    "    keywords = json_data.get('keywords', [])\n",
    "    \n",
    "    # article: news_textbody > news_textmore > news_add (paragraph titles are h3)\n",
    "    article = soup.find('div', id=\"news_textbody\").text\n",
    "    if soup.find_all('div', id=\"news_textmore\") != []:\n",
    "        for textmore in soup.find_all('div', id=\"news_textmore\"):\n",
    "            article += ('\\n' + textmore.text)\n",
    "    if soup.find_all('div', class_=\"news_add\") != []:\n",
    "        for newsadd in soup.find_all('div', class_=\"news_add\"):\n",
    "            if newsadd.h3 != None:\n",
    "                newsadd.h3.extract()\n",
    "            article += ('\\n' + newsadd.text)\n",
    "            \n",
    "    return {\n",
    "        'id':url.split('/')[-1].split('.html')[0],\n",
    "        'title':title.strip(),\n",
    "        'article':article.strip(),\n",
    "        'genre':genre,\n",
    "        'keywords':keywords,\n",
    "        'url':url,\n",
    "        'datePublished':date,\n",
    "        'dateModified':date_m\n",
    "    }\n",
    "\n",
    "# for old web normal\n",
    "def make_datetime_normal_old(hmd, time):\n",
    "    year, month, day = hmd[:4], hmd[4:6], hmd[6:]\n",
    "    hour, minute = time.split('時')\n",
    "    minute = minute.strip('分')\n",
    "    if len(hour) == 1:\n",
    "        hour = '0' + hour\n",
    "    if len(minute) == 1:\n",
    "        minute = '0' + minute\n",
    "    return f\"{year}-{month}-{day}T{hour}:{minute}\"\n",
    "\n",
    "def scrape_one_old(html, url):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # title, date, genre, keyword\n",
    "    title = soup.find('span', class_=\"contentTitle\").text.strip()\n",
    "    hmd_ = url.split('/')[-2]\n",
    "    time_ = soup.find('span', id=\"news_time\").text\n",
    "    date = make_datetime_normal_old(hmd_, time_)\n",
    "    genre = [k for k in soup.find('meta', attrs={'name':'keywords'}).get('content').split(',') if k not in ['NHK','ニュース', 'NHK NEWS WEB','ＮＨＫ','ＮＨＫニュース','']]\n",
    "    \n",
    "    # article: news_textbody > news_textmore > news_add (paragraph titles are h3)\n",
    "    article = soup.find(['div','p'], id=\"news_textbody\").text\n",
    "    if soup.find_all(['div','p'], id=\"news_textmore\") != []:\n",
    "        for textmore in soup.find_all(['div','p'], id=\"news_textmore\"):\n",
    "            article += ('\\n' + textmore.text)\n",
    "    if soup.find_all(['div','p'], class_=\"news_add\") != []:\n",
    "        for newsadd in soup.find_all(['div','p'], class_=\"news_add\"):\n",
    "            if newsadd.h3 != None:\n",
    "                newsadd.h3.extract()\n",
    "            article += ('\\n' + newsadd.text)\n",
    "            \n",
    "    return {\n",
    "        'id':url.split('/')[-1].split('.html')[0],\n",
    "        'title':title.strip(),\n",
    "        'article':article.strip(),\n",
    "        'genre':genre,\n",
    "        'keywords':[],\n",
    "        'url':url,\n",
    "        'datePublished':date,\n",
    "        'dateModified':\"\"\n",
    "    }\n",
    "\n",
    "def get_archiveurl(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    html = str(driver.page_source.encode('utf-8'))\n",
    "    snap = re.search(r'(times between|1 time|times).*?<a href=\"(.+?)\">', html)\n",
    "    #if snap == None:\n",
    "        #return None\n",
    "    archiveurl = 'https://web.archive.org' + snap.group(2)\n",
    "    return archiveurl\n",
    "\n",
    "def js(dic, year):\n",
    "    with open(f'nhkweb{year}.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    with open(f'nhkweb{year}.json', 'w', encoding='utf-8') as f:\n",
    "        if dic['id'] not in [x['id'] for x in data]:\n",
    "            data.append(dic)\n",
    "        else:\n",
    "            for i, d in enumerate(data):\n",
    "                if dic['id'] == d['id']:\n",
    "                    data[i] = dic\n",
    "        data = sorted(data, key=lambda x:x['id'])\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def geturl(year=2019):\n",
    "    idnormal = pd.read_json(f'nhkweb{year}.json', encoding='utf-8')['id'].tolist()\n",
    "    existurl = pd.read_csv('linknormal.txt', encoding='utf-8', header=None)[0].tolist()\n",
    "    nolink = pd.read_csv('nolinknormal.txt', encoding='utf-8', header=None)[0].tolist()\n",
    "    urls = set(existurl) - set(nolink)\n",
    "    return sorted([url for url in urls if (url.split('.html')[0].split('/')[-1] not in idnormal) and f'html/{year}' in url])\n",
    "\n",
    "def checkwrongid(): # check wrong ID in newswebeasy\n",
    "    df = pd.read_json('nhkwebeasy.json', encoding='utf-8')\n",
    "    print(len(df))\n",
    "    df['normalID'] = df['url_normal'].apply(lambda x:x.split('/')[-1].strip('.html'))\n",
    "    return df[df['id'] != df['normalID']]['id'].tolist()\n",
    "\n",
    "def wrongscrape():\n",
    "    wrongids = wrongid()\n",
    "    existurl = pd.read_csv('linknormal.txt', encoding='utf-8', header=None)[0].tolist()[::-1]\n",
    "    for ID in wrongids:\n",
    "        for url in existurl:\n",
    "            if ID in url:\n",
    "                print(url.split('/*/')[-1])\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>article</th>\n      <th>genre</th>\n      <th>keywords</th>\n      <th>url</th>\n      <th>datePublished</th>\n      <th>dateModified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>k10010239321000</td>\n      <td>栃木 鹿沼市 ５９世帯に避難指示</td>\n      <td>栃木県鹿沼市は今後の雨で、土砂災害が発生するおそれがあるとして、すでに避難勧告を出している日...</td>\n      <td>[社会]</td>\n      <td>[]</td>\n      <td>http://www.nhk.or.jp/news/html/20150917/k10010...</td>\n      <td>2015-09-17T23:52</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>k10010000621000</td>\n      <td>ウィリアム王子 震災の犠牲者に花束</td>\n      <td>イギリス王室のウィリアム王子は東日本大震災の被災地の宮城県石巻市と女川町を訪れ、震災の犠牲者...</td>\n      <td>[社会]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20150301/k1001...</td>\n      <td>2015-03-01T17:37</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>k10010000861000</td>\n      <td>健やかな成長願う「流しびな」</td>\n      <td>桃の節句を前に、人形作りが盛んなさいたま市岩槻区で子どもの健やかな成長を願って紙のひな人形を...</td>\n      <td>[科学・文化]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20150301/k1001...</td>\n      <td>2015-03-01T23:32</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>k10010000991000</td>\n      <td>企業の約４０％ 「正社員不足感じる」</td>\n      <td>雇用情勢の改善傾向が続くなか、企業の４０％近くが正社員の不足を感じているという調査結果がまと...</td>\n      <td>[ビジネス]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20150302/k1001...</td>\n      <td>2015-03-02T04:16</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>k10010001851000</td>\n      <td>ラグビーＷ杯 会場の１２都市が決定</td>\n      <td>２０１９年に日本で開かれるラグビーワールドカップで試合会場となる１２の都市が発表され、東日本...</td>\n      <td>[スポーツ]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20150302/k1001...</td>\n      <td>2015-03-02T21:52</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>k10015475931000</td>\n      <td>チンアナゴなど産卵の撮影成功 世界初</td>\n      <td>海の底から顔をのぞかせる姿が人気のウナギの仲間、チンアナゴとニシキアナゴ。この産卵の様子の撮...</td>\n      <td>[科学・文化]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20150215/k1001...</td>\n      <td>2015-02-15T19:45</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>783</th>\n      <td>k10015477531000</td>\n      <td>ネットで税務申告ｅ‐Ｔａｘ手続き簡素化へ</td>\n      <td>政府は、インターネットを使って税金の申告などができる「ｅーＴａｘ」を使いやすくするため、再来...</td>\n      <td>[ビジネス]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20150216/k1001...</td>\n      <td>2015-02-16T04:12</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>784</th>\n      <td>k10015513531000</td>\n      <td>リベリア エボラ患者減少で学校再開</td>\n      <td>エボラ出血熱の流行が続いてきた西アフリカのリベリアで１６日、地元の学校が７か月ぶりに再開し、...</td>\n      <td>[国際]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20150217/k1001...</td>\n      <td>2015-02-17T10:32</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>785</th>\n      <td>k10015770111000</td>\n      <td>サクラ開花予想 全国的におおむね平年並み</td>\n      <td>気象会社などが行っている最新のサクラの開花予想によりますと、この春の開花は全国的におおむね平...</td>\n      <td>[社会]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20150226/k1001...</td>\n      <td>2015-02-26T17:04</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>786</th>\n      <td>k10015825611000</td>\n      <td>ナガスクジラの声 海底地震計で捉えた</td>\n      <td>絶滅のおそれがあるとされる、世界で２番目に大きい「ナガスクジラ」とみられる鳴き声が、日本の近...</td>\n      <td>[科学・文化]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20150228/k1001...</td>\n      <td>2015-02-28T18:36</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>787 rows × 8 columns</p>\n</div>",
      "text/plain": "                  id                 title  \\\n0    k10010239321000      栃木 鹿沼市 ５９世帯に避難指示   \n1    k10010000621000     ウィリアム王子 震災の犠牲者に花束   \n2    k10010000861000        健やかな成長願う「流しびな」   \n3    k10010000991000    企業の約４０％ 「正社員不足感じる」   \n4    k10010001851000     ラグビーＷ杯 会場の１２都市が決定   \n..               ...                   ...   \n782  k10015475931000    チンアナゴなど産卵の撮影成功 世界初   \n783  k10015477531000  ネットで税務申告ｅ‐Ｔａｘ手続き簡素化へ   \n784  k10015513531000     リベリア エボラ患者減少で学校再開   \n785  k10015770111000  サクラ開花予想 全国的におおむね平年並み   \n786  k10015825611000    ナガスクジラの声 海底地震計で捉えた   \n\n                                               article    genre keywords  \\\n0    栃木県鹿沼市は今後の雨で、土砂災害が発生するおそれがあるとして、すでに避難勧告を出している日...     [社会]       []   \n1    イギリス王室のウィリアム王子は東日本大震災の被災地の宮城県石巻市と女川町を訪れ、震災の犠牲者...     [社会]       []   \n2    桃の節句を前に、人形作りが盛んなさいたま市岩槻区で子どもの健やかな成長を願って紙のひな人形を...  [科学・文化]       []   \n3    雇用情勢の改善傾向が続くなか、企業の４０％近くが正社員の不足を感じているという調査結果がまと...   [ビジネス]       []   \n4    ２０１９年に日本で開かれるラグビーワールドカップで試合会場となる１２の都市が発表され、東日本...   [スポーツ]       []   \n..                                                 ...      ...      ...   \n782  海の底から顔をのぞかせる姿が人気のウナギの仲間、チンアナゴとニシキアナゴ。この産卵の様子の撮...  [科学・文化]       []   \n783  政府は、インターネットを使って税金の申告などができる「ｅーＴａｘ」を使いやすくするため、再来...   [ビジネス]       []   \n784  エボラ出血熱の流行が続いてきた西アフリカのリベリアで１６日、地元の学校が７か月ぶりに再開し、...     [国際]       []   \n785  気象会社などが行っている最新のサクラの開花予想によりますと、この春の開花は全国的におおむね平...     [社会]       []   \n786  絶滅のおそれがあるとされる、世界で２番目に大きい「ナガスクジラ」とみられる鳴き声が、日本の近...  [科学・文化]       []   \n\n                                                   url     datePublished  \\\n0    http://www.nhk.or.jp/news/html/20150917/k10010...  2015-09-17T23:52   \n1    http://www3.nhk.or.jp/news/html/20150301/k1001...  2015-03-01T17:37   \n2    http://www3.nhk.or.jp/news/html/20150301/k1001...  2015-03-01T23:32   \n3    http://www3.nhk.or.jp/news/html/20150302/k1001...  2015-03-02T04:16   \n4    http://www3.nhk.or.jp/news/html/20150302/k1001...  2015-03-02T21:52   \n..                                                 ...               ...   \n782  http://www3.nhk.or.jp/news/html/20150215/k1001...  2015-02-15T19:45   \n783  http://www3.nhk.or.jp/news/html/20150216/k1001...  2015-02-16T04:12   \n784  http://www3.nhk.or.jp/news/html/20150217/k1001...  2015-02-17T10:32   \n785  http://www3.nhk.or.jp/news/html/20150226/k1001...  2015-02-26T17:04   \n786  http://www3.nhk.or.jp/news/html/20150228/k1001...  2015-02-28T18:36   \n\n    dateModified  \n0                 \n1                 \n2                 \n3                 \n4                 \n..           ...  \n782               \n783               \n784               \n785               \n786               \n\n[787 rows x 8 columns]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('nhkweb2015.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>article</th>\n      <th>genre</th>\n      <th>keywords</th>\n      <th>url</th>\n      <th>datePublished</th>\n      <th>dateModified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3432</th>\n      <td>k10010505261000</td>\n      <td>北アルプス 蓮華岳 男性が滑落し救助要請</td>\n      <td>長野県と富山県にまたがる北アルプスの蓮華岳で、スキー場ではない斜面を滑るバックカントリースキ...</td>\n      <td>[社会]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160501/k1001...</td>\n      <td>2016-05-01T06:44</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3433</th>\n      <td>k10010505271000</td>\n      <td>北アルプスの奥穂高岳 滑落事故相次ぎ１人意識不明</td>\n      <td>先月３０日夜、岐阜県の北アルプスの奥穂高岳の岩場近くで、登山者の１人が滑落したという通報があ...</td>\n      <td>[社会]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160501/k1001...</td>\n      <td>2016-05-01T07:05</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3434</th>\n      <td>k10010505281000</td>\n      <td>Ｇ７エネルギー相会合 きょう北九州で開幕</td>\n      <td>Ｇ７＝主要７か国のエネルギー相会合が１日、北九州市で開幕します。エネルギーの安定調達に向けて...</td>\n      <td>[国際, ビジネス]</td>\n      <td>[サミット]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160501/k1001...</td>\n      <td>2016-05-01T05:51</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3435</th>\n      <td>k10010505291000</td>\n      <td>水俣病の公式確認から６０年 全面的な解決は見通せず</td>\n      <td>公害の原点と言われる水俣病が公式に確認されてから、１日でちょうど６０年となります。今も新たに...</td>\n      <td>[社会]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160501/k1001...</td>\n      <td>2016-05-01T08:35</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3436</th>\n      <td>k10010505301000</td>\n      <td>首相 きょうから欧州５か国などを歴訪</td>\n      <td>安倍総理大臣は１日からヨーロッパ５か国などを歴訪し、各国の首脳らと会談することにしています。...</td>\n      <td>[国際, 政治]</td>\n      <td>[サミット]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160501/k1001...</td>\n      <td>2016-05-01T04:33</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4583</th>\n      <td>k10010541101000</td>\n      <td>「ペッタンコ祭」赤ちゃんの成長願いおでこにはんこ</td>\n      <td>赤ちゃんの健やかな成長を願っておでこにはんこを押す「初山大祭」が群馬県館林市の神社で行われて...</td>\n      <td>[地域, 暮らし]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160531/k1001...</td>\n      <td>2016-05-31T12:14</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4584</th>\n      <td>k10010541441000</td>\n      <td>バター不足解消へ 新たに６０００トンの輸入決定</td>\n      <td>ここ数年、店頭での品薄が続いているバターについて、農林水産省はこの夏は気温が高く原料の生乳の...</td>\n      <td>[ビジネス, 暮らし]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160531/k1001...</td>\n      <td>2016-05-31T16:55</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4585</th>\n      <td>k10010541451000</td>\n      <td>クルーズ船から失踪の中国人相次ぐ 不法入国の新手口か</td>\n      <td>中国の富裕層などが観光に使うクルーズ船の日本への寄港が急増するなか、入国したあと船に戻らずに...</td>\n      <td>[社会]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160531/k1001...</td>\n      <td>2016-05-31T17:06</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4586</th>\n      <td>k10010541521000</td>\n      <td>受動喫煙で死亡 年間１万５０００人と推計</td>\n      <td>他人のたばこの煙を吸い込む「受動喫煙」によって肺がんや脳卒中などで死亡する人は、国内で年間お...</td>\n      <td>[社会]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160531/k1001...</td>\n      <td>2016-05-31T17:56</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4587</th>\n      <td>k10010541581000</td>\n      <td>北朝鮮ミサイル失敗「ムスダン」か 韓国「一層強力な制裁」</td>\n      <td>北朝鮮が３１日早く、東部から新型の中距離弾道ミサイル「ムスダン」１発の発射を試みたものの失敗...</td>\n      <td>[国際]</td>\n      <td>[北朝鮮情勢]</td>\n      <td>http://www3.nhk.or.jp/news/html/20160531/k1001...</td>\n      <td>2016-05-31T18:29</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>1156 rows × 8 columns</p>\n</div>",
      "text/plain": "                   id                         title  \\\n3432  k10010505261000          北アルプス 蓮華岳 男性が滑落し救助要請   \n3433  k10010505271000      北アルプスの奥穂高岳 滑落事故相次ぎ１人意識不明   \n3434  k10010505281000          Ｇ７エネルギー相会合 きょう北九州で開幕   \n3435  k10010505291000     水俣病の公式確認から６０年 全面的な解決は見通せず   \n3436  k10010505301000            首相 きょうから欧州５か国などを歴訪   \n...               ...                           ...   \n4583  k10010541101000      「ペッタンコ祭」赤ちゃんの成長願いおでこにはんこ   \n4584  k10010541441000       バター不足解消へ 新たに６０００トンの輸入決定   \n4585  k10010541451000    クルーズ船から失踪の中国人相次ぐ 不法入国の新手口か   \n4586  k10010541521000          受動喫煙で死亡 年間１万５０００人と推計   \n4587  k10010541581000  北朝鮮ミサイル失敗「ムスダン」か 韓国「一層強力な制裁」   \n\n                                                article        genre keywords  \\\n3432  長野県と富山県にまたがる北アルプスの蓮華岳で、スキー場ではない斜面を滑るバックカントリースキ...         [社会]       []   \n3433  先月３０日夜、岐阜県の北アルプスの奥穂高岳の岩場近くで、登山者の１人が滑落したという通報があ...         [社会]       []   \n3434  Ｇ７＝主要７か国のエネルギー相会合が１日、北九州市で開幕します。エネルギーの安定調達に向けて...   [国際, ビジネス]   [サミット]   \n3435  公害の原点と言われる水俣病が公式に確認されてから、１日でちょうど６０年となります。今も新たに...         [社会]       []   \n3436  安倍総理大臣は１日からヨーロッパ５か国などを歴訪し、各国の首脳らと会談することにしています。...     [国際, 政治]   [サミット]   \n...                                                 ...          ...      ...   \n4583  赤ちゃんの健やかな成長を願っておでこにはんこを押す「初山大祭」が群馬県館林市の神社で行われて...    [地域, 暮らし]       []   \n4584  ここ数年、店頭での品薄が続いているバターについて、農林水産省はこの夏は気温が高く原料の生乳の...  [ビジネス, 暮らし]       []   \n4585  中国の富裕層などが観光に使うクルーズ船の日本への寄港が急増するなか、入国したあと船に戻らずに...         [社会]       []   \n4586  他人のたばこの煙を吸い込む「受動喫煙」によって肺がんや脳卒中などで死亡する人は、国内で年間お...         [社会]       []   \n4587  北朝鮮が３１日早く、東部から新型の中距離弾道ミサイル「ムスダン」１発の発射を試みたものの失敗...         [国際]  [北朝鮮情勢]   \n\n                                                    url     datePublished  \\\n3432  http://www3.nhk.or.jp/news/html/20160501/k1001...  2016-05-01T06:44   \n3433  http://www3.nhk.or.jp/news/html/20160501/k1001...  2016-05-01T07:05   \n3434  http://www3.nhk.or.jp/news/html/20160501/k1001...  2016-05-01T05:51   \n3435  http://www3.nhk.or.jp/news/html/20160501/k1001...  2016-05-01T08:35   \n3436  http://www3.nhk.or.jp/news/html/20160501/k1001...  2016-05-01T04:33   \n...                                                 ...               ...   \n4583  http://www3.nhk.or.jp/news/html/20160531/k1001...  2016-05-31T12:14   \n4584  http://www3.nhk.or.jp/news/html/20160531/k1001...  2016-05-31T16:55   \n4585  http://www3.nhk.or.jp/news/html/20160531/k1001...  2016-05-31T17:06   \n4586  http://www3.nhk.or.jp/news/html/20160531/k1001...  2016-05-31T17:56   \n4587  http://www3.nhk.or.jp/news/html/20160531/k1001...  2016-05-31T18:29   \n\n     dateModified  \n3432               \n3433               \n3434               \n3435               \n3436               \n...           ...  \n4583               \n4584               \n4585               \n4586               \n4587               \n\n[1156 rows x 8 columns]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['datePublished'].str.startswith('2016-05')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "#options.headless = True\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: window was already closed\n  (Session info: chrome=80.0.3987.132)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2d7e969f2c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# get archive URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0marchiveurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_archiveurl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e43317fa45b8>\u001b[0m in \u001b[0;36mget_archiveurl\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0msnap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(times between|1 time|times).*?<a href=\"(.+?)\">'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m#if snap == None:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \"\"\"\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: window was already closed\n  (Session info: chrome=80.0.3987.132)\n"
     ]
    }
   ],
   "source": [
    "year = 2015\n",
    "urls = pd.read_csv(f'linknormal.txt', header=None)\n",
    "urls = sorted(urls[urls[0].str.contains(f'html/{year}')][0].tolist())\n",
    "id_exist = set(pd.read_json(f'nhkweb{year}.json')['id'].tolist())\n",
    "\n",
    "for url in urls:\n",
    "    # check URL\n",
    "    ID = url.split('.html')[0].split('/')[-1]\n",
    "    if ID in id_exist:\n",
    "        continue\n",
    "\n",
    "    # get archive URL\n",
    "    archiveurl = get_archiveurl(url)\n",
    "\n",
    "    # request\n",
    "    response = requests.get(archiveurl)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "    elif response.status_code == 504:\n",
    "        response = requests.get(archiveurl)\n",
    "        if response.status_code == 504:\n",
    "            continue\n",
    "        html = response.text\n",
    "    time.sleep(4)\n",
    "\n",
    "    # scrape\n",
    "    url_true = 'htt' + url.split('/htt')[-1]\n",
    "\n",
    "    try:\n",
    "        dic = scrape_one_new(html, url_true)\n",
    "    except:\n",
    "        dic = scrape_one_old(html, url_true)\n",
    "    js(dic, year)\n",
    "    id_exist.add(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'k10010627901000',\n 'title': '台風５号 北日本～東北の太平洋側 暴風・高波に警戒',\n 'article': '台風５号は日本の東の海上を北上していて、気象庁は北日本から東北にかけての太平洋側を中心に暴風や高波に警戒するよう呼びかけています。\\n気象庁の観測によりますと、台風５号は９日午前６時には、仙台市の東２７０キロの海上を１時間に２５キロの速さで北へ進んでいます。中心の気圧は９８０ヘクトパスカル、最大風速は３０メートル、最大瞬間風速は４０メートルで中心の東側２８０キロ以内と西側１７０キロ以内では風速２５メートル以上の暴風が吹いています。台風はこのあとも北上を続け、９日夜には北海道の東の海上に進み、１０日の朝には千島の近海で温帯低気圧に変わる見込みです。東北の太平洋側では、海はうねりを伴って大しけとなっていて、１０日は北海道の太平洋側でも大しけとなる見込みです。また、北海道の太平洋側では９日夜にかけて非常に強い風が吹き、最大風速は２０メートル、最大瞬間風速は３０メートルに達すると予想されています。気象庁は北日本から東北にかけての太平洋側を中心に、暴風や高波に警戒するよう呼びかけています。',\n 'genre': ['気象', '災害'],\n 'keywords': [],\n 'url': 'http://www3.nhk.or.jp/news/html/20160809/k10010627901000.html',\n 'datePublished': '2016-08-09T06:29',\n 'dateModified': ''}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_true = 'htt' + driver.current_url.split('/htt')[-1]\n",
    "html = driver.page_source.encode('utf-8')\n",
    "try:\n",
    "    dic = scrape_one_new(html, url_true)\n",
    "except:\n",
    "    dic = scrape_one_old(html, url_true)\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "js(dic, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "articles:  10740\n"
    },
    {
     "data": {
      "text/plain": "[('国際', 4223),\n ('社会', 2827),\n ('政治', 1525),\n ('ビジネス', 1341),\n ('スポーツ', 943),\n ('気象・災害', 792),\n ('科学・文化', 783),\n ('暮らし', 519),\n ('地域', 423)]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check category\n",
    "\n",
    "year = 2017\n",
    "\n",
    "with open(f'nhkweb{year}.json','r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "print('articles: ', len(data))\n",
    "genre = Counter()\n",
    "for dic in data:\n",
    "    for g in dic['genre']:\n",
    "        genre[g] += 1\n",
    "genre.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre <> keywords\n",
    "with open(f'nhkweb{year}.json','r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "category = ['社会', '国際', 'ビジネス', 'スポーツ', '政治', '科学・文化', '暮らし', '地域', '気象・災害']\n",
    "for i, dic in enumerate(data):\n",
    "    newgenre = []\n",
    "    newkey = []\n",
    "    for j in dic['genre']:\n",
    "        if j in category:\n",
    "            newgenre.append(j)\n",
    "        elif j == \"災害\" or j == \"気象\":\n",
    "            newgenre.append('気象・災害')\n",
    "        elif j == \"科学・医療\" or j == \"文化・エンタメ\" or j == \"科学\":\n",
    "            newgenre.append('科学・文化')\n",
    "        elif j == \"暮らし文化\":\n",
    "            newgenre.append('暮らし')\n",
    "            newgenre.append('科学・文化')\n",
    "        elif j == \"経済\":\n",
    "            newgenre.append('ビジネス')\n",
    "        else:\n",
    "            newkey.append(j)\n",
    "    for j in dic['keywords']:\n",
    "        if j in category:\n",
    "            newgenre.append(j)\n",
    "        elif j == \"科学・医療\" or j == \"文化・エンタメ\" or j == \"科学\":\n",
    "            newgenre.append('科学・文化')\n",
    "        elif j == \"暮らし文化\":\n",
    "            newgenre.append('暮らし')\n",
    "            newgenre.append('科学・文化')\n",
    "        elif j == \"災害\" or j == \"気象\":\n",
    "            newgenre.append('気象・災害')\n",
    "        else:\n",
    "            newkey.append(j)\n",
    "    data[i]['genre'] = list(set(newgenre))\n",
    "    data[i]['keywords'] = list(set(newkey))\n",
    "\n",
    "with open(f'nhkweb{year}.json','w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "k10011141491000    1\nk10011000931000    1\nk10010934981000    1\nk10010951261000    1\nk10010933321000    1\n                  ..\nk10011177701000    1\nk10011195271000    1\nk10010962891000    1\nk10011073211000    1\nk10011211931000    1\nName: id, Length: 10740, dtype: int64"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(f'nhkweb{year}.json').id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}