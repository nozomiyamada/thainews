{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit159cf5e9823545708744fa9c9ccfe5dc",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, json, csv, requests, time, glob, tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_one_new(html, url):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    json_data = json.loads(soup.find_all(\"script\", type=\"application/ld+json\")[-1].text)\n",
    "    title = json_data.get('headline', soup.find('span', class_='contentTitle').text)\n",
    "    date = json_data.get('datePublished', re.search(r'datetime:.*?(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2})', str(html)).group(1))\n",
    "    date_m = json_data.get('dateModified', '')\n",
    "    genre = json_data.get('genre', [])\n",
    "    if genre == []:\n",
    "        genre = [k for k in soup.find('meta', attrs={'name':'keywords'}).get('content').split(',') if k not in ['NHK','ニュース', 'NHK NEWS WEB']]\n",
    "    keywords = json_data.get('keywords', [])\n",
    "    article = soup.find('div', id=\"news_textbody\").text\n",
    "    if soup.find_all('div', id=\"news_textmore\") != []:\n",
    "        for textmore in soup.find_all('div', id=\"news_textmore\"):\n",
    "            article += ('\\n' + textmore.text)\n",
    "    if soup.find_all('div', class_=\"news_add\") != []:\n",
    "        for newsadd in soup.find_all('div', class_=\"news_add\"):\n",
    "            if newsadd.h3 != None:\n",
    "                newsadd.h3.extract()\n",
    "            article += ('\\n' + newsadd.text)\n",
    "            \n",
    "    return {\n",
    "        'id':url.split('/')[-1].split('.html')[0],\n",
    "        'title':title,\n",
    "        'article':article.strip(),\n",
    "        'genre':genre,\n",
    "        'keywords':keywords,\n",
    "        'url':url,\n",
    "        'datePublished':date,\n",
    "        'dateModified':date_m\n",
    "    }\n",
    "\n",
    "# for old web normal\n",
    "def make_date_normal_old(hmd,time):\n",
    "    year, month, day = hmd[:4], hmd[4:6], hmd[6:]\n",
    "    hour, minute = time.split('時')\n",
    "    minute = minute.strip('分')\n",
    "    if len(hour) == 1:\n",
    "        hour = '0' + hour\n",
    "    if len(minute) == 1:\n",
    "        minute = '0' + minute\n",
    "    return f\"{year}-{month}-{day}T{hour}:{minute}\"\n",
    "\n",
    "def scrape_one_old(html, url):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    title = soup.find('span', class_=\"contentTitle\").text.strip()\n",
    "    hmd_ = url.split('/')[-2]\n",
    "    time_ = soup.find('span', id=\"news_time\").text\n",
    "    date = make_date_normal_old(hmd_, time_)\n",
    "    genre = [k for k in soup.find('meta', attrs={'name':'keywords'}).get('content').split(',') if k not in ['NHK','ニュース', 'NHK NEWS WEB','ＮＨＫ','ＮＨＫニュース','']]\n",
    "    article = soup.find(['div','p'], id=\"news_textbody\").text\n",
    "    if soup.find_all(['div','p'], id=\"news_textmore\") != []:\n",
    "        for textmore in soup.find_all(['div','p'], id=\"news_textmore\"):\n",
    "            article += ('\\n' + textmore.text)\n",
    "    if soup.find_all(['div','p'], class_=\"news_add\") != []:\n",
    "        for newsadd in soup.find_all(['div','p'], class_=\"news_add\"):\n",
    "            if newsadd.h3 != None:\n",
    "                newsadd.h3.extract()\n",
    "            article += ('\\n' + newsadd.text)\n",
    "            \n",
    "    return {\n",
    "        'id':url.split('/')[-1].split('.html')[0],\n",
    "        'title':title,\n",
    "        'article':article.strip(),\n",
    "        'genre':genre,\n",
    "        'keywords':[],\n",
    "        'url':url,\n",
    "        'datePublished':date,\n",
    "        'dateModified':\"\"\n",
    "    }\n",
    "\n",
    "def get_archiveurl_from_id(ID, date):\n",
    "    url1 = f'https://web.archive.org/web/*/https://www3.nhk.or.jp/news/html/{date}/k{ID}1000.html'\n",
    "    url2 = f'https://web.archive.org/web/*/http://www3.nhk.or.jp/news/html/{date}/k{ID}1000.html'\n",
    "    \n",
    "    driver.get(url1)\n",
    "    time.sleep(3)\n",
    "    html = str(driver.page_source.encode('utf-8'))\n",
    "    snap = re.search(r'(times between|1 time|times).*?<a href=\"(.+?)\">', html)\n",
    "    archiveurl = 'https://web.archive.org' + snap.group(2)\n",
    "    \n",
    "    if 'nhk' not in archiveurl:\n",
    "        driver.get(url2)\n",
    "        time.sleep(3)\n",
    "        html = str(driver.page_source.encode('utf-8'))\n",
    "        snap = re.search(r'(times between|1 time|times).*?<a href=\"(.+?)\">', html)\n",
    "        archiveurl = 'https://web.archive.org' + snap.group(2)\n",
    "    return None if 'nhk' not in archiveurl else archiveurl\n",
    "\n",
    "def get_article_from_archiveurl(archiveurl):\n",
    "    response = requests.get(archiveurl)\n",
    "    time.sleep(2)\n",
    "    html = response.text\n",
    "    url_true = 'http' + archiveurl.split('/http')[-1]\n",
    "    if 'This page is not available on the web' in html:\n",
    "        return None\n",
    "    try:\n",
    "        try:\n",
    "            dic = scrape_one_new(html, url_true)\n",
    "        except:\n",
    "            dic = scrape_one_old(html, url_true)\n",
    "        return dic\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def js(dic, year):\n",
    "    if dic == None:\n",
    "        return\n",
    "    with open(f'nhkweb{year}.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    with open(f'nhkweb{year}.json', 'w', encoding='utf-8') as f:\n",
    "        if dic['id'] not in [x['id'] for x in data]:\n",
    "            data.append(dic)\n",
    "        else:\n",
    "            for i, d in enumerate(data):\n",
    "                if dic['id'] == d['id']:\n",
    "                    data[i] = dic\n",
    "        data = sorted(data, key=lambda x:x['id'])\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>article</th>\n      <th>genre</th>\n      <th>keywords</th>\n      <th>url</th>\n      <th>datePublished</th>\n      <th>dateModified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>k10011760881000</td>\n      <td>僕、迷惑ですか？</td>\n      <td>東日本大震災のあと、「僕」は売れっ子になりました。売り上げは何倍にも跳ね上がり、カジュアルだ...</td>\n      <td>[暮らし]</td>\n      <td>[]</td>\n      <td>https://www3.nhk.or.jp/news/html/20190104/k100...</td>\n      <td>2019-01-04T12:32:01+09:00</td>\n      <td>2019-01-04T12:32:02+09:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>k10011764791000</td>\n      <td>日米欧もアジアも 2018年 株価下落 景気先行きに不安根強く</td>\n      <td>ニューヨーク株式市場は31日、2018年最後の取り引きが行われ、ダウ平均株価は値上がりして取...</td>\n      <td>[ビジネス]</td>\n      <td>[株価・為替]</td>\n      <td>http://www3.nhk.or.jp/news/html/20190101/k1001...</td>\n      <td>2019-01-01T08:55</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>k10011764801000</td>\n      <td>ロシア スパイ容疑で米国人の男拘束 米ロ関係一層悪化へ</td>\n      <td>ロシアの治安当局は、スパイ活動をしていた疑いでアメリカ人の男をモスクワ市内で拘束しました。米...</td>\n      <td>[国際]</td>\n      <td>[]</td>\n      <td>https://www3.nhk.or.jp/news/html/20190101/k100...</td>\n      <td>2019-01-01T08:39</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>k10011764811000</td>\n      <td>独 メルケル首相 米欧の自国第一主義に懸念 新年前に演説</td>\n      <td>ドイツのメルケル首相は新年を前にした恒例のテレビ演説で「国際協調という確かなものが圧力にさら...</td>\n      <td>[国際]</td>\n      <td>[]</td>\n      <td>http://www3.nhk.or.jp/news/html/20190101/k1001...</td>\n      <td>2019-01-01T09:02</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>k10011764821000</td>\n      <td>マーライオンも摩天楼も 新年祝う花火が照らす</td>\n      <td>日本より１時間遅れで新年を迎えたシンガポールでは、観光名所として知られるマーライオンの像の前...</td>\n      <td>[国際]</td>\n      <td>[国際５]</td>\n      <td>http://www3.nhk.or.jp/news/html/20190101/k1001...</td>\n      <td>2019-01-01T09:13</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                id                            title  \\\n0  k10011760881000                         僕、迷惑ですか？   \n1  k10011764791000  日米欧もアジアも 2018年 株価下落 景気先行きに不安根強く   \n2  k10011764801000      ロシア スパイ容疑で米国人の男拘束 米ロ関係一層悪化へ   \n3  k10011764811000     独 メルケル首相 米欧の自国第一主義に懸念 新年前に演説   \n4  k10011764821000           マーライオンも摩天楼も 新年祝う花火が照らす   \n\n                                             article   genre keywords  \\\n0  東日本大震災のあと、「僕」は売れっ子になりました。売り上げは何倍にも跳ね上がり、カジュアルだ...   [暮らし]       []   \n1  ニューヨーク株式市場は31日、2018年最後の取り引きが行われ、ダウ平均株価は値上がりして取...  [ビジネス]  [株価・為替]   \n2  ロシアの治安当局は、スパイ活動をしていた疑いでアメリカ人の男をモスクワ市内で拘束しました。米...    [国際]       []   \n3  ドイツのメルケル首相は新年を前にした恒例のテレビ演説で「国際協調という確かなものが圧力にさら...    [国際]       []   \n4  日本より１時間遅れで新年を迎えたシンガポールでは、観光名所として知られるマーライオンの像の前...    [国際]    [国際５]   \n\n                                                 url  \\\n0  https://www3.nhk.or.jp/news/html/20190104/k100...   \n1  http://www3.nhk.or.jp/news/html/20190101/k1001...   \n2  https://www3.nhk.or.jp/news/html/20190101/k100...   \n3  http://www3.nhk.or.jp/news/html/20190101/k1001...   \n4  http://www3.nhk.or.jp/news/html/20190101/k1001...   \n\n               datePublished               dateModified  \n0  2019-01-04T12:32:01+09:00  2019-01-04T12:32:02+09:00  \n1           2019-01-01T08:55                             \n2           2019-01-01T08:39                             \n3           2019-01-01T09:02                             \n4           2019-01-01T09:13                             "
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('nhkweb2019.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get missing url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>150</th>\n      <td>1001176639</td>\n      <td>https://www3.nhk.or.jp/news/html/20190103/k100...</td>\n      <td>20190103</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>1001176640</td>\n      <td>http://www3.nhk.or.jp/news/html/20190103/k1001...</td>\n      <td>20190103</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>1001176641</td>\n      <td>http://www3.nhk.or.jp/news/html/20190103/k1001...</td>\n      <td>20190103</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>1001176642</td>\n      <td>https://www3.nhk.or.jp/news/html/20190103/k100...</td>\n      <td>20190103</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>1001176643</td>\n      <td>http://www3.nhk.or.jp/news/html/20190103/k1001...</td>\n      <td>20190103</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>1001176644</td>\n      <td>http://www3.nhk.or.jp/news/html/20190103/k1001...</td>\n      <td>20190103</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>1001176645</td>\n      <td>http://www3.nhk.or.jp/news/html/20190103/k1001...</td>\n      <td>20190103</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>1001176646</td>\n      <td>https://www3.nhk.or.jp/news/html/20190103/k100...</td>\n      <td>20190103</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>1001176647</td>\n      <td>https://www3.nhk.or.jp/news/html/20190103/k100...</td>\n      <td>20190103</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>1001176648</td>\n      <td>https://www3.nhk.or.jp/news/html/20190103/k100...</td>\n      <td>20190103</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             id                                                url      date\n150  1001176639  https://www3.nhk.or.jp/news/html/20190103/k100...  20190103\n151  1001176640  http://www3.nhk.or.jp/news/html/20190103/k1001...  20190103\n152  1001176641  http://www3.nhk.or.jp/news/html/20190103/k1001...  20190103\n153  1001176642  https://www3.nhk.or.jp/news/html/20190103/k100...  20190103\n154  1001176643  http://www3.nhk.or.jp/news/html/20190103/k1001...  20190103\n155  1001176644  http://www3.nhk.or.jp/news/html/20190103/k1001...  20190103\n156  1001176645  http://www3.nhk.or.jp/news/html/20190103/k1001...  20190103\n157  1001176646  https://www3.nhk.or.jp/news/html/20190103/k100...  20190103\n158  1001176647  https://www3.nhk.or.jp/news/html/20190103/k100...  20190103\n159  1001176648  https://www3.nhk.or.jp/news/html/20190103/k100...  20190103"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('nhkweb2019.json')\n",
    "data = data[['id', 'url']]\n",
    "data.id = data.id.apply(lambda x:x[1:-4])\n",
    "data['date'] = data.url.apply(lambda x:x.split('news/html/')[-1].split('/')[0])\n",
    "data.iloc[150:160,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'https://web.archive.org/web/20190101072943/https://www3.nhk.or.jp/news/html/20190101/k10011765031000.html'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "get_archiveurl_from_id(1001176503, 20190101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1001176660\n"
    }
   ],
   "source": [
    "year = 2019\n",
    "\n",
    "for i in range(160, 300):\n",
    "    ID1, ID2 = data.iat[i,0], data.iat[i+1,0]\n",
    "    date1, date2 = data.iat[i,2], data.iat[i+1,2]\n",
    "\n",
    "    if int(ID1) + 1 == int(ID2): # continuous = no missing\n",
    "        continue\n",
    "    elif date1 == date2:  # not continuous, but in the same day\n",
    "        print(ID1)\n",
    "        for ID in range(int(ID1)+1, int(ID2)):\n",
    "            archiveurl = get_archiveurl_from_id(ID, date1)\n",
    "            if archiveurl != None:\n",
    "                dic = get_article_from_archiveurl(archiveurl)\n",
    "                js(dic, year)\n",
    "    else:  # not continuous, not in the same day\n",
    "        print(ID1)\n",
    "        is_date1 = True\n",
    "        for ID in range(int(ID1)+1, int(ID2)):\n",
    "            if is_date1:\n",
    "                archiveurl = get_archiveurl_from_id(ID, date1)\n",
    "                if archiveurl:\n",
    "                    dic = get_article_from_archiveurl(archiveurl)\n",
    "                    js(dic, year)\n",
    "                else:\n",
    "                    archiveurl = get_archiveurl_from_id(ID, date2)\n",
    "                    if archiveurl:\n",
    "                        dic = get_article_from_archiveurl(archiveurl)\n",
    "                        js(dic, year)\n",
    "                        is_date1 = False\n",
    "            else:\n",
    "                archiveurl = get_archiveurl_from_ID(ID, date2)\n",
    "                if archiveurl:\n",
    "                        js(dic, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.page_source.encode(\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://web.archive.org/web/20190101010957/htt...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://web.archive.org/web/20190101014546/htt...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://web.archive.org/web/20190101023520/htt...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://web.archive.org/web/20190101034607/htt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://web.archive.org/web/20190101042642/htt...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>https://web.archive.org/web/20190106112232/htt...</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>https://web.archive.org/web/20190106112234/htt...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>https://web.archive.org/web/20190106135151/htt...</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>https://web.archive.org/web/20190106135200/htt...</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>https://web.archive.org/web/20190203041912/htt...</td>\n    </tr>\n  </tbody>\n</table>\n<p>183 rows × 1 columns</p>\n</div>",
      "text/plain": "                                                     0\n0    https://web.archive.org/web/20190101010957/htt...\n1    https://web.archive.org/web/20190101014546/htt...\n2    https://web.archive.org/web/20190101023520/htt...\n3    https://web.archive.org/web/20190101034607/htt...\n4    https://web.archive.org/web/20190101042642/htt...\n..                                                 ...\n178  https://web.archive.org/web/20190106112232/htt...\n179  https://web.archive.org/web/20190106112234/htt...\n180  https://web.archive.org/web/20190106135151/htt...\n181  https://web.archive.org/web/20190106135200/htt...\n182  https://web.archive.org/web/20190203041912/htt...\n\n[183 rows x 1 columns]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2019\n",
    "urls = pd.read_csv('link19.txt', header=None)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n"
    },
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ID already exist\n",
    "data = pd.read_json('nhkweb2019.json')\n",
    "ids = data.id.tolist()\n",
    "urls = pd.read_csv('link19.txt', header=None)\n",
    "urls = [url for url in urls[0] if url.split('/')[-1].split('.html')[0] not in ids]\n",
    "print(len(urls))\n",
    "urls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "81000.html\n{'id': 'k10011765681000', 'title': '「サンマ投げ」2000匹を人々が拾う 豊漁祈願 静岡', 'article': '一年の豊漁と漁の安全を願って集まった人たちにサンマを投げてふるまう新年恒例の行事が静岡県西伊豆町の港で行われました。\\n\\n\\n\\nこの行事は西伊豆町の安良里港で毎年１月２日の漁船の乗り初めに合わせて行われています。接岸された地元所属の大型サンマ漁船「第135豊幸丸」に乗組員15人が乗り込み、用意したおよそ2000匹のサンマを次々と港に投げていきました。サンマは豊幸丸が去年10月に岩手県沖400キロの太平洋で取り、２日のために冷凍保存していたものだということです。集まった人の中には持参したバケツや袋がいっぱいになるほど拾い集める姿も見られ、用意したサンマはおよそ10分ほどでなくなりました。参加した人たちは「毎年この行事を楽しみにしています。ことしもたくさん拾えたのでよい年になりそうです」とか、「サンマが手に当たって痛かったですが、早速焼いて食べます」などと話していました。', 'genre': ['暮らし', '地域'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765681000.html', 'datePublished': '2019-01-02T14:26', 'dateModified': ''}\nhttps://web.archive.org/web/20190102060117/https://www3.nhk.or.jp/news/html/20190102/k10011765571000.html\n{'id': 'k10011765571000', 'title': '大みそかから並びました！豪華景品「仙台初売り」に長い列', 'article': '豪華な景品で知られる伝統の「仙台初売り」が行われ、朝早くから多くの人たちがお正月の風物詩を楽しみました。\\n江戸時代から続く「仙台初売り」は、商人の心意気を示そうと豪華な景品をつけたことが始まりとされ、毎年１月２日に行われています。仙台市中心部ではこの伝統を守ろうとデパートや大型店なども初売りを２日に統一しています。老舗のお茶の店では午前７時の開店前に、豪華な景品や福袋などを目当てに大みそかから並んだ人たちなど100人以上が列を作りました。この店では１万円以上の買い物をした先着100人に、高級なお茶や電気ポットなどが入った最大70センチほどの茶箱を景品として渡しています。商品を買った人はうれしそうに茶箱を抱え、早速、中身を見るなどして平成最後のお正月の風物詩を楽しんでいました。この初売りのために北海道から来たという30代の男性は「寒かったですが、２泊３日待ったかいがありました。新しい元号になっても初売りに行き続けたいです」と笑顔で話していました。地元の50代の男性は「初売りは仙台の自慢なので、これからも地元の人たちの力で伝統を守っていきたいです」と話していました。', 'genre': ['暮らし', '地域'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765571000.html', 'datePublished': '2019-01-02T11:53', 'dateModified': ''}\nhttps://web.archive.org/web/20190102060142/https://www3.nhk.or.jp/news/html/20190101/k10011765011000.html\n{'id': 'k10011765011000', 'title': '京都の伏見稲荷大社 初詣でにぎわう', 'article': '商売繁盛の神様として知られる京都の伏見稲荷大社には元日、大勢の人たちが初詣に訪れていました。\\n京都市伏見区にある伏見稲荷大社は、全国にある「お稲荷さん」の総本宮で、五穀豊じょうや商売繁盛の神様として知られています。元日は御利益を求める人たちが本殿の前に長い列を作り、順番にさい銭を投げ入れては商売繁盛や家族の健康などを願って手を合わせていました。赤い鳥居が連なり、“インスタ映えする”と人気の千本鳥居を抜けた先には、「おもかる石」と呼ばれる石があり、持ち上げた時に軽いと感じると願いがかなうとされています。訪れた人たちは願い事を思い浮かべながら両手で持ち上げ、ことし１年の運試しをしていました。神奈川県から訪れた50代の女性は「毎年来ていますが、ことしはちょっと軽かったかなと感じました。笑って過ごせるような１年にしたいなと思います」と話していました。また、京都市内から家族と訪れた７歳の女の子は「賢くなれるようにお願いしました」とドイツ人留学生の男性は「ちょっと重かった。世界の平和を願いました」と話していました。', 'genre': ['暮らし', '地域'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190101/k10011765011000.html', 'datePublished': '2019-01-01T12:33', 'dateModified': ''}\nhttps://web.archive.org/web/20190102060217/https://www3.nhk.or.jp/news/html/20190101/k10011764961000.html\n{'id': 'k10011764961000', 'title': 'デパートで初売り 開店前から長い列', 'article': '１日、一部のデパートでは、平成最後の初売りが行われました。このうち、東京・池袋のデパートには福袋などを目当てに開店前から買い物客の長い列ができていました。\\n\\n\\n\\nこの店では、1500種類、およそ15万個の福袋を用意し、なかでも婦人用のストールや傘などの雑貨が入った5000円台の福袋が人気を集めていました。また、野球盤やボードゲームなど長年、親しまれているおもちゃが入っていたり平成元年に作られた日本酒や梅酒を集めたりした“平成”を振り返ってもらおうという福袋や2019年にちなんで201万9000円で販売される純金で作られたえとの「いのしし」の置物などが注目を集めていました。買い物に訪れた女性は、「初売りに来ないと新年が始まりません。たくさん買って１年に弾みをつけたいです」と話していました。\\n\\n\\n\\n西武池袋本店販売促進部の新宮明課長は、「平成最後の正月にたくさんの人に来ていただき本当にありがたい。個人消費は伸び悩んでいるが、ニーズをしっかり捉えて商品を展開していきたい」と話していました。デパート業界では、ことし10月の消費税率の引き上げで、消費の落ち込みも懸念されていることから、各社では、初売り商戦に力を入れて、売り上げに弾みをつけたいとしています。', 'genre': ['暮らし'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190101/k10011764961000.html', 'datePublished': '2019-01-01T11:45', 'dateModified': ''}\nhttps://web.archive.org/web/20190102060222/https://www3.nhk.or.jp/news/html/20190101/k10011764911000.html\n{'id': 'k10011764911000', 'title': '初日の出フライトを満喫 成田空港', 'article': 'およそ5000メートルの上空から初日の出を楽しむ、新春恒例のフライトが成田空港で行われました。\\n\\n\\n\\nこの「初日の出フライト」は、天候にかかわらず初日の出を見られることなどから、日本航空と成田空港会社が毎年、行っていて、ことしは家族連れなど208人が参加しました。\\n\\n\\n\\n参加者を乗せた旅客機は、午前６時すぎに成田空港を離陸し、千葉県館山沖の高度およそ5000メートルを旋回して、初日の出を待ちました。そして、空が徐々にオレンジ色に染まり、午前６時40分ごろ、初日の出が見え始めると、機内も明るく照らされ乗客は歓声を上げて、写真におさめていました。\\n\\n\\n\\nこのあと富士山の上空に向かうと、雲の切れ間から雪化粧した「初富士」が現れ、乗客たちはその姿を眺めていました。家族と参加した４歳の男の子は、「きれいなだいだい色が見られて楽しかったです」と話していました。また、さいたま市の21歳の女性は、「空から見る初日の出は新鮮でした。ことしは社会人になるので、太陽のように明るい１年にしたいです」と話していました。', 'genre': ['暮らし'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190101/k10011764911000.html', 'datePublished': '2019-01-01T10:43', 'dateModified': ''}\nhttps://web.archive.org/web/20190102060300/https://www3.nhk.or.jp/news/html/20190102/k10011765671000.html\n{'id': 'k10011765671000', 'title': '北野天満宮 正月恒例の書き初め 京都', 'article': '学問の神様 菅原道真をまつる京都の北野天満宮で正月恒例の書き初めが行われ、親子連れなどが新年の誓いや願いを思い思いにしたためました。\\n京都市上京区の北野天満宮では、書道の達人とも伝えられている菅原道真にあやかって、毎年正月に書き初めが行われています。初日の２日は朝から親子連れなどが使い慣れた書道の道具を持って境内を訪れ、長机に向かって姿勢を正して筆をとりました。えとの「亥」や、ことしで終わる「平成」といった思い思いの字を丁寧に書き上げていました。「猛進」と書いた中学３年生の男の子は「高校受験があるので合格に向けて猛勉強しようと思います」と話していました。「万福」と書いた50代の女性は「ここで書き初めをすると新年を迎えたと実感します。朝ドラで『まんぷく』もやっていますし、たくさんの福が訪れる一年になってほしいと思い書きました」と話していました。書き初めは４日まで行われ、作品はすべて今月18日から境内で展示されるということです。', 'genre': ['科学・文化', '地域'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765671000.html', 'datePublished': '2019-01-02T14:19', 'dateModified': ''}\nhttps://web.archive.org/web/20190102060628/https://www3.nhk.or.jp/news/html/20190102/k10011765721000.html\n{'id': 'k10011765721000', 'title': 'ドイツでも車暴走 新年の広場に突入 ５人けが 外国人狙ったか', 'article': 'ドイツ西部で元日の未明、50歳の男が運転する車が広場にいた人たちなどを次々にはねて、シリア人など５人が重軽傷を負いました。捜査当局は外国人を狙った犯行との見方を示し、反移民感情が背景にあるものとみて調べています。\\nドイツ西部の町ボトロップで１日未明、新年を祝うため広場に集まっていた人たちに車が突っ込み、シリア人やアフガニスタン人など合わせて４人がけがをしました。このうち46歳の女性が重傷です。車はその場から走り去ったあと、隣の町エッセンでも歩行者に突っ込み、１人がけがをしました。警察によりますと、車を運転していたのは50歳のドイツ人の男で、殺人未遂の容疑で逮捕されました。現地のメディアは、男は取り押さえられたとき外国人への差別的な発言をしていたと伝えています。地元の内務当局のトップは外国人を狙った犯行との見方を示し、反移民感情が背景にあるものとみて調べています。ドイツのメルケル政権は中東やアフリカから多くの難民や移民を受け入れてきましたが、去年８月には東部の町で外国人排斥を唱える人々による暴動が起きたほか、地方選挙で難民の受け入れに反対する右派政党が躍進するなど、難民や移民に対する風当たりが強まっています。', 'genre': ['国際'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765721000.html', 'datePublished': '2019-01-02T14:43', 'dateModified': ''}\nhttps://web.archive.org/web/20190102060639/https://www3.nhk.or.jp/news/html/20190102/k10011765551000.html\n{'id': 'k10011765551000', 'title': 'ヨーロッパ 真冬の海や川に飛び込んで新年祝う', 'article': '新年を迎えたヨーロッパでは、真冬の冷たい海や川に飛び込んで新しい年の到来を祝う行事が各地で行われました。\\n\\n\\n\\n\\nこのうち、北海に面するオランダ南西部のスヘーベニンゲンでは１日、大勢の人たちが海に飛び込んで新年を祝いました。およそ１万人の参加者たちは、ニット帽に水着という格好で歓声を上げながら砂浜を勢いよく走り出すと、次々と海に入っていきました。そして、寒さに震えながらも、波に合わせてジャンプしたり肩まで海につかったりして、お祝いムードを楽しんでいました。\\n\\n\\n\\n\\nまた、イタリアの首都ローマでは、20メートル近い高さの橋の上から川に飛び込む新年恒例の行事が行われました。この行事は、第２次世界大戦が終わった直後の1946年から続けられてきたということで、ことしは４人の勇気ある男性が橋の欄干から川に飛び込みました。中には両手にイタリアの国旗を掲げて飛び込んだり、見事な宙返りを披露したりする人もいて、集まった観衆から大きな声援や拍手が送られていました。４人のうち最高齢の66歳の男性は、「水は冷たかったが、無事に飛び込めてよかった」と笑顔で話していました。', 'genre': ['国際'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765551000.html', 'datePublished': '2019-01-02T08:07', 'dateModified': ''}\nhttps://web.archive.org/web/20190102060737/https://www3.nhk.or.jp/news/html/20190102/k10011765741000.html\n{'id': 'k10011765741000', 'title': '箱根駅伝往路 東洋大が２年連続優勝 青山学院大は６位', 'article': '関東の大学対抗で競う「箱根駅伝」が始まり、往路では東洋大が２年連続で優勝し、往路と復路の総合で５連覇を目指す青山学院大は６位と出遅れ、３日の復路に臨みます。\\n95回目の箱根駅伝にはオープン参加の関東学生連合を含む23チームが出場しました。２日は往路が行われ、東京 大手町から神奈川県箱根町までの５つの区間107.5キロのコースで争われました。１区ではスタート直後に大東文化大の選手が転倒するアクシデントがあり、そこから20キロほど走り続けて何とかたすきをつなぐ場面もありました。この１区では東洋大がトップに立ち、２区も２位で３区を迎えました。ただ３区では総合５連覇を目指す青山学院大のキャプテン 森田歩希選手が区間新記録の走りで８位から先頭に立ちました。４区では東洋大が巻き返し、２位でスタートした３年生の相澤晃選手が３キロを前に青山学院大を抜き去り、後続を引き離して区間記録を大幅に更新する走りを見せました。その東洋大は２位に順位を上げた東海大をリードして「山登り」の５区に入り、５時間26分31秒のタイムで２年連続７回目の往路優勝を果たしました。２位は１分14秒差で東海大、３位は２分44秒差で国学院大でした。青山学院大は４区と５区で順位を落とし、東洋大と５分30秒差の６位で３日の復路での逆転を狙います。', 'genre': ['スポーツ'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765741000.html', 'datePublished': '2019-01-02T14:27', 'dateModified': ''}\nhttps://web.archive.org/web/20190102060741/https://www3.nhk.or.jp/news/html/20190102/k10011765701000.html\n{'id': 'k10011765701000', 'title': 'ことし52歳 カズ「１試合でも多く出場 １つでも多くゴール」', 'article': 'サッカーＪリーグの現役最年長でことし52歳になるカズ、三浦知良選手がふるさとの静岡市で「経験と情熱で１試合でも多く出場し、１つでも多くのゴールを決めたい」とことしの抱負を語りました。\\n三浦選手は、お正月にふるさとの静岡市で子どものころに所属していたクラブチームの選手などと新年最初のサッカーを楽しむのが恒例となっています。２日は、朝からグラウンドに姿を見せましたが、先月痛めた足の状態が万全ではないということで、大事を取ってボールは蹴りませんでした。三浦選手は、子どもたちと一緒に餅つきなどをして交流し、「よいしょ」と大きな声をかけるなどして笑顔を見せていました。Ｊリーグの現役最年長でＪ２の横浜ＦＣに所属する三浦選手は、来月26日に52歳の誕生日を迎えます。三浦選手は、「開幕までの２か月間にどこまで自分を追い込み、体を仕上げることができるか楽しみだ。コンディションの調整は、昨シーズンも大変だったが経験と情熱で１試合でも多く出場し１ゴールでも多く決めたい」などとシーズンへの抱負を語りました。三浦選手は、今月、グアムで自主トレーニングを行ったあと、所属するチームに合流し来月24日の開幕戦に備えます。', 'genre': ['サッカー', 'スポーツ'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765701000.html', 'datePublished': '2019-01-02T14:07', 'dateModified': ''}\nhttps://web.archive.org/web/20190102062807/https://www3.nhk.or.jp/news/html/20190102/k10011765791000.html\n{'id': 'k10011765791000', 'title': '86歳 三浦雄一郎さん 南米最高峰登頂へ出発', 'article': '86歳の冒険家 三浦雄一郎さんが今月、南米最高峰「アコンカグア」の登頂に挑戦するため、２日、現地アルゼンチンに向けて出発しました。\\n\\n\\n\\n冒険家でプロスキーヤーの三浦雄一郎さんは６年前、80歳の時にエベレストの登頂に成功して世界最高齢での登頂記録を塗り替え、そのあとも次の登山を検討してきました。今月、三浦さんは南米大陸最高峰のアコンカグア登頂に86歳で挑戦することになり、２日、羽田空港からフランス経由で現地アルゼンチンへ向けて出発しました。空港では三浦さんが校長を務める通信制高校の生徒たち15人が集まって出発式を行い、「日本から全力で応援しています」とエールを送ると、三浦さんが「皆さんの激励で元気と勇気をもらいました」と応えていました。三浦さんが挑戦するアコンカグアは、アルゼンチンのアンデス山脈にあり、標高およそ6960ｍで、登頂成功率は30％程度と難しい山とされています。出発を前に三浦さんは「新年早々おいしいものをたくさん食べて馬力がついたと思います。この馬力で頑張ってきたい」と話していました。三浦さんはアルゼンチンに到着後、標高4200ｍ付近のベースキャンプに入って登山の準備を進め、今月21日ごろの登頂を目指す計画です。登頂後は氷河をスキーで滑降して下山するということです。', 'genre': ['社会'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765791000.html', 'datePublished': '2019-01-02T15:23', 'dateModified': ''}\nhttps://web.archive.org/web/20190102062808/https://www3.nhk.or.jp/news/html/20190102/k10011765841000.html\n{'id': 'k10011765841000', 'title': 'デイサービス送迎車が事故 105歳女性と76歳男性死亡 茨城', 'article': '２日午前、茨城県北茨城市の交差点でデイサービス施設の送迎車がほかの車と出会い頭に衝突し、施設の利用者の105歳と76歳の男女２人が死亡しました。\\n２日午前９時ごろ、北茨城市中郷町の信号機のない交差点で、デイサービス施設の利用者を送迎していた軽乗用車と、もう１台の乗用車が出会い頭に衝突しました。警察によりますと、送迎車の後部座席には施設の利用者の山形清江さん（105）と吉原征夫さん（76）が乗っていて、頭などを打って病院に運ばれましたが２人とも死亡しました。また双方の車の運転手もそれぞれ軽いけがをしました。現場の交差点は市の郊外にある田んぼや畑が広がる一角にあり、見通しはよいものの、信号機のほか一時停止の標識などは設置されていないということです。警察は当時の状況について運転手たちから話を聴くなどして事故の原因を調べています。', 'genre': ['社会'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765841000.html', 'datePublished': '2019-01-02T15:21', 'dateModified': ''}\nhttps://web.archive.org/web/20190102062809/https://www3.nhk.or.jp/news/html/20190102/k10011765831000.html\n{'id': 'k10011765831000', 'title': '北陸新幹線 運転再開', 'article': '北陸新幹線は金沢駅構内の信号トラブルの影響で金沢と長野の間の上下線で運転を見合わせていましたが、午後３時６分に運転を再開しました。', 'genre': ['社会'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765831000.html', 'datePublished': '2019-01-02T15:18', 'dateModified': ''}\nhttps://web.archive.org/web/20190102062810/https://www3.nhk.or.jp/news/html/20190102/k10011765781000.html\n{'id': 'k10011765781000', 'title': '「船おろし」漁船からみかんや菓子投げ大漁願う 神奈川 鎌倉', 'article': '砂浜に引き上げた漁船からみかんやお菓子を投げて配り、一年の安全と大漁を願う「船おろし」と呼ばれる行事が神奈川県鎌倉市で行われました。\\n\\n\\n\\n「船おろし」は鎌倉市の漁業関係者が一年の安全と大漁を願って毎年１月２日に行っています。２日、由比ヶ浜海岸の砂浜には大漁旗で飾られた漁船10隻余りが引き上げられ、快晴に恵まれたこともあって大勢の人が集まりました。漁業関係者が黄金色で縁起がよいとされるみかんやお菓子を船の上から投げて配ると、集まった人たちは手を伸ばして受け取っていました。横浜市から家族で訪れた40代の男性は「子どもたちがお菓子やみかんをもらいました。ことしは家族みんなで健康な年にしたいです」と話していました。鎌倉漁業協同組合の原実代表理事は「昨年は台風の多い年だったので、ことしは台風が少なく安心な漁ができるといいです。取れた魚を皆さんに食べてもらいたい」と話していました。', 'genre': ['暮らし', '地域'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765781000.html', 'datePublished': '2019-01-02T15:10', 'dateModified': ''}\nhttps://web.archive.org/web/20190102074116/https://www3.nhk.or.jp/news/html/20190102/k10011765871000.html\n{'id': 'k10011765871000', 'title': '台湾独立の動きには武力行使も辞さず 中国 習主席', 'article': '中国の習近平国家主席は２日、台湾政策について演説し、統一を目指す考えを改めて強調したうえで、独立の動きや外部の干渉に対して、武力行使も排除しない強い姿勢を示しました。台湾の蔡英文政権や、台湾への武器売却などを進める方針を示すアメリカのトランプ政権をけん制したものです。\\n習主席は２日、中国が1979年の元日に台湾に平和的な統一を呼びかける文書を発表してから40年になるのを記念して、北京で演説しました。この中で、「台湾は中国の一部分で、台湾海峡の両岸が１つの中国に属するという、歴史的、法律的な事実はいかなる勢力も変えられない」と述べ、統一を目指す考えを改めて強調しました。そのうえで、香港などで実施する「１国２制度」こそが最良の形だとして統一の在り方を模索する考えなどを示し、「１つの中国」の原則を堅持することを基礎として台湾の政党や団体に対話を呼びかけました。一方で台湾独立の動きや外部勢力の干渉に対しては「あらゆる必要な選択肢を保持する」として武力行使も排除しない強い姿勢を示しました。名指しは避けながらも、独立志向が強いと見なす台湾の蔡英文政権や、台湾への武器の売却などを進める方針を示すアメリカのトランプ政権をけん制したものです。台湾では来年はじめに総統選挙が行われる予定で、習主席としては蔡政権に揺さぶりをかけるねらいもあるものとみられます。', 'genre': ['国際'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765871000.html', 'datePublished': '2019-01-02T16:18', 'dateModified': ''}\nhttps://web.archive.org/web/20190102074451/https://www3.nhk.or.jp/news/html/20190102/k10011765891000.html\n{'id': 'k10011765891000', 'title': '北陸新幹線 運転再開も遅れや運休続く 帰省客ら「困った」', 'article': '北陸新幹線は２日午後、ＪＲ金沢駅の構内で起きた信号トラブルのため金沢と長野の間の上下線で最大でおよそ２時間にわたって運転を見合わせ、帰省客などに影響が出ました。\\nＪＲ西日本によりますと、２日午後１時すぎ、ＪＲ金沢駅の構内にある北陸新幹線の信号機が切り替わらなくなるトラブルがありました。この影響で北陸新幹線は金沢と長野の間の上下線で最大でおよそ２時間にわたって運転を見合わせました。ＪＲ金沢駅の新幹線の改札前には帰省客など多くの人たちが集まり、運転再開がいつになるのか駅員に問い合わせたり、掲示板に表示される情報を確認したりする人の姿が見られました。妻と一緒に新幹線で東京に戻る予定だった60代の男性は「突然のことでどうしていいか分からず困っています。運転再開までもう少し待とうと思います」と話していました。金沢駅で東京から来る友人を待っていた20代の女性は「友達が情報がなくて困っていると連絡があったので、私が掲示板を見て分かる範囲の状況を伝えています。一緒に遊びにいく予定があったので困っています」と話していました。北陸新幹線は午後３時すぎに全線で運転を再開しましたが一部の列車に運休や遅れが出ています。ＪＲ西日本によりますと、金沢駅に出入りする列車の線路を切り替える装置が正常に動かず、信号機が切り替わらなかったということで、詳しい原因を調べています。', 'genre': ['社会'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765891000.html', 'datePublished': '2019-01-02T16:37', 'dateModified': ''}\nhttps://web.archive.org/web/20190102074459/https://www3.nhk.or.jp/news/html/20190102/k10011765881000.html\n{'id': 'k10011765881000', 'title': '帝京大 連覇「９」で止まる 天理大に敗退 ラグビー大学選手権', 'article': 'ラグビーの全国大学選手権は準決勝が行われ、大会10連覇を狙った帝京大が天理大に７対29で敗れ、連覇は９で止まりました。', 'genre': ['ラグビー', 'スポーツ'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765881000.html', 'datePublished': '2019-01-02T16:05', 'dateModified': ''}\nhttps://web.archive.org/web/20190102074501/https://www3.nhk.or.jp/news/html/20190102/k10011765761000.html\n{'id': 'k10011765761000', 'title': '日ロ交渉 Ｇ20サミット… 外交手腕問われる１年に 安倍首相', 'article': '安倍総理大臣は戦後日本外交の総決算を掲げ、年明けから積極的に首脳外交を展開する方針で、今月下旬の日ロ首脳会談では平和条約の条文作成作業の開始を確認したい考えです。そして、ことしのＧ20大阪サミットに合わせて再度、首脳会談を行い平和条約交渉の大枠合意を目指す方針で、まさに外交手腕が問われる１年となりそうです。\\n\\n\\n\\n第２次安倍内閣発足後７年目に入った安倍総理大臣は戦後日本外交の総決算を掲げ、年明けから積極的に首脳外交を展開する方針で、今月９日からはＥＵから３月に離脱するイギリスなどを訪問することにしています。その後、21日にもロシアで日ロ首脳会談に臨むほか、世界の政財界のリーダーらが一堂に会してスイスで開かれる世界経済フォーラムの年次総会「ダボス会議」でスピーチを行うとともに、会議に出席するアメリカのトランプ大統領との会談も調整しています。このうち日ロ首脳会談で安倍総理大臣は、先に「平和条約を締結したあと歯舞群島と色丹島を引き渡す」とした1956年の日ソ共同宣言を基礎に交渉を加速することで合意したのを踏まえ、平和条約の条文作成作業の開始を確認したい考えです。そしてことし６月、みずからが議長を務め日本で初めて開催されるＧ20大阪サミット＝主要20か国の首脳会議に合わせて日本を訪れるプーチン大統領と再度、首脳会談を行い、平和条約交渉の大枠合意を目指す方針です。ただロシア側からは日本側をけん制する意見が相次いでいるほか、アメリカ軍の基地が北方領土に置かれる可能性に懸念を示す指摘も出ていて、交渉は難航が予想されます。また安倍総理大臣は、アメリカと中国の対立などで世界経済の先行きに不透明感が増す中で、Ｇ20サミットの議長として、自由貿易の推進のほか海洋プラスチックごみの問題や気候変動の対策で各国の協調体制の再構築を目指す方針で、まさに外交手腕が問われる１年となりそうです。\\n\\n\\n\\n\\n公明党の山口代表は2日、東京都内で街頭演説し、ことし北方領土問題を含むロシアとの平和条約交渉が進展することに期待を示しました。この中で「４月１日には次の時代の元号が公表され５月１日に改元される見通しだ。新しい時代を迎えるとともに外交の面でもことし日本が大きな役割を果たしていかなければならない」と述べました。そして「今月には日ロ首脳会談が行われ、６月のＧ20サミットの際にも首脳会談が行われるだろう。北方四島の帰属の問題をはっきりさせたうえで平和条約の締結を推進すべきだ。旧島民が自由に往来できるようにすることや共同経済活動が実施できるようにすることを含めて、解決を推進すべきだ」と述べ、交渉の進展に期待を示しました。また政権運営について「国民の信頼を損なうようなことがあれば、きちんとただし信頼を確保していかなければならず、国会運営でも数の力で一辺倒に押し切るようなことは厳に慎まなければならない。スピード感を持って意思決定することも必要だが、真摯（しんし）に議論を尽くし、幅広い合意形成を生み出すことも重要だ」と指摘しました。そのうえで「ことしは亥年で統一地方選挙と参議院選挙が相次いで行われる。大事な議席だ」と訴え、議席の確保を目指す考えを示しました。', 'genre': ['北方領土', '政治'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765761000.html', 'datePublished': '2019-01-02T15:54', 'dateModified': ''}\nhttps://web.archive.org/web/20190102074509/https://www3.nhk.or.jp/news/html/20190102/k10011765801000.html\n{'id': 'k10011765801000', 'title': '北方領土への米軍展開にロシア懸念 日本は払拭できるか', 'article': '日本とロシアは、今月予定されている首脳会談や外相会談をはじめ、ことし平和条約交渉を加速させることにしています。ロシアとしては、日本がアメリカに対してどこまで主権を主張して、ロシアが抱く安全保障上の懸念を払拭（ふっしょく）できるかなど、日本の対応を見極めながら交渉に臨むものとみられます。\\n日本とロシアの両首脳は、平和条約の締結後に歯舞群島と色丹島を引き渡すと明記された1956年の日ソ共同宣言に基づいて交渉を加速させることで去年合意しました。これを受けて交渉責任者となったロシアのラブロフ外相が今月、河野外務大臣と会談を行うのに続き、プーチン大統領がロシアで安倍総理大臣と会談する予定です。プーチン大統領は先月、沖縄のアメリカ軍基地の現状を引き合いに出しながら「日本にどれほどの主権があるのか分からない」と述べ、北方領土を仮に引き渡した場合、アメリカの意向に沿ってアメリカ軍が展開することもありうるのではないかと強い懸念を示しました。またプーチン大統領は、日本がアメリカから導入する新型迎撃ミサイルシステム「イージス・アショア」についても「防衛のための兵器とは思えない」と述べるなど、警戒感をあらわにしています。ロシアとしては、日本がアメリカに対してどこまで主権を主張してロシアが抱く安全保障上の懸念を払拭できるかなど、日本の対応を見極めながら平和条約交渉に臨むものとみられます。\\n\\n\\nロシアが日本との領土交渉を加速させる背景について、政治学者のアレクセイ・マカルキン氏はＮＨＫの取材で「日本と個別に親しくすることでＧ７加盟各国への良い影響を期待した試みではないか」と述べ、日本との関係改善を進めることで国際社会から孤立している現状の打開につなげたいねらいがあると指摘しました。その一方で「歯舞、色丹を日本に引き渡すことはロシアが戦争の結果得たものを手放すということだ。これは国民の間に否定的な感情を引き起こす」と述べ、とりわけ年金制度改革など国民に痛みを伴う改革で支持率が落ち込む中、プーチン大統領としては世論の動向も気にしながら難しい決断を迫られるだろうという見通しを示しました。', 'genre': ['北方領土', '北方領土 トップ', '国際'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765801000.html', 'datePublished': '2019-01-02T15:46', 'dateModified': ''}\nhttps://web.archive.org/web/20190102074514/https://www3.nhk.or.jp/news/html/20190102/k10011765851000.html\n{'id': 'k10011765851000', 'title': 'テニス 錦織圭 今季初戦ストレート勝ち 準々決勝へ', 'article': 'テニスの錦織圭選手がオーストラリアで今シーズンの初戦に臨み、アメリカの選手にストレート勝ちして準々決勝に進みました。\\n世界ランキング９位の錦織選手は、オーストラリア東部のブリスベンで行われているツアー大会で今シーズンの初戦を迎えました。この大会は今月中旬に始まる四大大会の初戦、全豪オープンの前哨戦で、第２シードの錦織選手は２日の２回戦で世界63位でアメリカのデニス・クドラ選手と対戦しました。錦織選手は第１セット、クドラ選手の時速200キロ近い高速サーブに苦しめられましたが、そのサーブにミスが出始めた第11ゲームで深い位置を狙ったリターンでポイントを奪うなど相手のサービスゲームをブレークし、７－５で取りました。第２セットは第１ゲームからライン際を突く精度の高いショットでポイントを重ね、絶妙なドロップショットを決めるなどネットプレーもさえて、６－２で取りました。錦織選手はセットカウント２対０のストレート勝ちで今シーズンの初戦を制し、準々決勝に進みました。準々決勝では、おととしのツアーファイナルで優勝した世界19位、ブルガリアのグリゴール・ディミトロフ選手と対戦します。\\n\\n\\n錦織選手は試合後の記者会見で「シーズン初戦を終えてまずはほっとしている。サーブが良かったり大事なところでリターンが決まったり、いいポイントも多くあった。久しぶりの試合で、緊張はたぶんいつも以上にあったと思うが、１試合目にしては十分な試合だった。少しずつリズムをつかめていけたらいい」と振り返りました。次の準々決勝でおととしのツアーファイナルで優勝した世界19位、ブルガリアのディミトロフ選手と対戦することについて「ディミトロフ選手と対戦できることにわくわくしている。タフな試合になると思うが、次もまたいいテニスができると思う」と話していました。', 'genre': ['テニス', 'スポーツ'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765851000.html', 'datePublished': '2019-01-02T15:29', 'dateModified': ''}\nhttps://web.archive.org/web/20190102085746/https://www3.nhk.or.jp/news/html/20190102/k10011765911000.html\n{'id': 'k10011765911000', 'title': '巨人 ドラフト１位投手 高橋優貴 地元茨城で自主トレ', 'article': 'プロ野球巨人にドラフト１位で入団した八戸学院大の高橋優貴投手が、地元の茨城県で自主トレーニングを行いました。\\n高橋投手は150キロを超える力強い速球が持ち味の左ピッチャーで、去年のドラフト会議で巨人に１位で指名されて入団しました。２日午後、中学生のころに所属した茨城県の少年野球チームのグラウンドで自主トレーニングを行い、報道陣に公開しました。高橋投手は毎年このグラウンドで年始めのトレーニングを行っているということで、少年野球時代のチームメイトとともにランニングやキャッチボールなど軽めのメニューで汗を流しました。トレーニングのあと取材に応じ、「プロ野球の世界は勝負だと思うので、その勝負に勝って１軍のマウンドに上がれるように頑張りたい」と抱負を話しました。そのうえで「新人王をとるという意気込みでやっていきたい。ジャイアンツの日本一に貢献できるように一つでも多く勝ちたい」とプロ１年目の目標を述べました。高橋投手は今月９日から始まる巨人の新人選手の合同自主トレーニングに参加して２月のキャンプに備えるということです。', 'genre': ['プロ野球', 'スポーツ'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765911000.html', 'datePublished': '2019-01-02T17:01', 'dateModified': ''}\nhttps://web.archive.org/web/20190102085754/https://www3.nhk.or.jp/news/html/20190102/k10011765861000.html\n{'id': 'k10011765861000', 'title': '体操 内村航平 初練習「けがなく過ごし東京五輪迎える」', 'article': '体操の内村航平選手がことし最初の練習に臨み、「けがのないシーズンを過ごして、万全な状態で来年の東京オリンピックを迎えられるようにしたい」と新年の目標を話しました。\\nオリンピックの個人総合で２連覇の内村選手は昨シーズン、ＮＨＫ杯で前人未到の10連覇を達成しましたが、世界選手権の個人総合はけがで欠場し、団体では銅メダルでした。内村選手は２日、東京 北区のナショナルトレーニングセンターでおよそ３時間、ことし最初の練習に臨みました。平行棒では棒をつかんで倒立する練習を繰り返したほか、つり輪でも倒立を行い、姿勢にぶれが出ないか確認していました。内村選手は練習のあと取材に応じ、「２年連続でけがをしているので、ことしは技の構成の難しさを落としてけがをしないことを最優先にシーズンを過ごし、万全な状態で来年の東京オリンピックを迎えられるようにしたい」と新年の目標を話しました。またことし最初の大会として４月の全日本選手権を予定し、「去年の全日本選手権では大きなミスをして11連覇を逃している。ことしはミスのない演技を見せて優勝したい」と意気込みを話しました。内村選手は今月、中国で合宿を行うなどして４月の全日本選手権に向け調整を進めることにしています。', 'genre': ['スポーツ'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765861000.html', 'datePublished': '2019-01-02T16:52', 'dateModified': ''}\nhttps://web.archive.org/web/20190102085755/https://www3.nhk.or.jp/news/html/20190102/k10011765821000.html\n{'id': 'k10011765821000', 'title': '地球から65億キロの天体に米の無人探査機が接近 過去最も遠い', 'article': 'ＮＡＳＡ＝アメリカ航空宇宙局は、無人探査機「ニューホライズンズ」が地球から65億キロ離れた天体に接近したと発表しました。これまでで最も遠い天体に近づいたことになり、ＮＡＳＡは宇宙探査の歴史を塗り替えたとしています。\\n13年前に打ち上げられたＮＡＳＡの探査機「ニューホライズンズ」は太陽系の外側に向かって飛行を続け、これまでに冥王星に近づいて観測するなどしてきました。ＮＡＳＡは１日、ニューホライズンズが太陽系の外縁部にある岩のような天体「ウルティマ・トゥーレ」に接近したと発表しました。この天体は地球からの距離がおよそ65億キロと、探査機が近づいた中ではこれまでで最も遠く、ＮＡＳＡは宇宙探査の歴史を塗り替えたとしています。探査機は天体からおよそ3500キロまで近づいて通過し、この際撮影した粗い画像を分析すると、天体の大きさは長さ35キロ、幅15キロほどで、ひょうたんのような形をしているということです。またひょうたんを横に倒したような状態で、中心の細くなっている部分を軸に回転していることが分かるとしています。太陽系の外縁部には、46億年前、太陽系が形成された当初の特徴を残す小惑星や岩や氷の天体が無数にあると考えられていて、今後、探査機から届く高精細な画像やデータを分析することで太陽系の成り立ちに迫る成果が得られるのではないかと期待されています。', 'genre': ['科学・文化', '国際'], 'keywords': [], 'url': 'https://www3.nhk.or.jp/news/html/20190102/k10011765821000.html', 'datePublished': '2019-01-02T16:51', 'dateModified': ''}\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f23b97aebec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "ids = data['id']\n",
    "for url in urls:\n",
    "\n",
    "    response = requests.get(url)\n",
    "    time.sleep(2)\n",
    "    html = response.text\n",
    "    url_true = 'http' + url.split('/http')[-1]\n",
    "    if 'This page is not available on the web' in html:\n",
    "        continue\n",
    "    \n",
    "    print(url)\n",
    "    \n",
    "    try:\n",
    "        dic = scrape_one_new(html, url_true)\n",
    "    except:\n",
    "        dic = scrape_one_old(html, url_true)\n",
    "    js(dic, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'k10011764801000',\n 'title': 'ロシア スパイ容疑で米国人の男拘束 米ロ関係一層悪化へ',\n 'article': 'ロシアの治安当局は、スパイ活動をしていた疑いでアメリカ人の男をモスクワ市内で拘束しました。米ロ関係が一段と悪化することになりそうです。\\nロシア連邦保安庁は、スパイ活動をしていた疑いでアメリカ人のポール・ウィラン容疑者をモスクワ市内で拘束したと31日発表しました。具体的にどのような活動をしていたかなど詳しいことは明らかにしていません。去年７月には、アメリカのワシントンに住むロシア人の女がロシア政府の指示を受けてアメリカの政治団体に潜入しスパイ活動をした疑いでアメリカの司法当局に逮捕され、ロシア政府が強く反発していました。アメリカとロシアの関係は、５年前のクリミア併合や、去年11月、ウクライナ海軍の艦船がロシア側に銃撃、拿捕（だほ）された事件、それに2016年のアメリカ大統領選挙でのいわゆるロシア疑惑などを受け悪化の一途をたどっています。今回、ロシア側がアメリカ人をスパイ容疑で拘束したことで米ロ関係が一段と悪化することになりそうです。',\n 'genre': ['国際'],\n 'keywords': [],\n 'url': 'https://www3.nhk.or.jp/news/html/20190101/k10011764801000.html',\n 'datePublished': '2019-01-01T08:39',\n 'dateModified': ''}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}