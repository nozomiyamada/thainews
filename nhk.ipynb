{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["# import & get article ID"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"oldest ID: 185875\nnewest ID: 197953\n502\n"}],"source":["import requests, json, os\n","from bs4 import BeautifulSoup as BS\n","\n","with open ('nhk.json', 'r') as f:\n","    ids = sorted(x['id'] for x in json.load(f))\n","    print('oldest ID: %s' % ids[0])\n","    print('newest ID: %s' % ids[-1])\n","    print(len(ids))"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["# Scrape"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["total_list = []\n","for i in range(197716, 199000):\n","    url = f\"https://www3.nhk.or.jp/nhkworld/th/news/{i}/\"\n","    response = requests.get(url)\n","    response.encoding='utf-8'\n","    if response.status_code == 200:\n","        dic = {}\n","        soup = BS(response.text, \"html.parser\")\n","        data = soup.find('script',type=\"application/ld+json\")\n","        data = json.loads(data.text)\n","        dic['headline'] = data['headline']\n","        dic['article'] = data['articleBody']\n","        dic['date'] = data['datePublished']\n","        dic['url'] = url\n","        dic['id'] = str(i)\n","        total_list.append(dic)\n","\n","with open ('nhk_new.json', 'w') as f:\n","    with open ('nhk.json', 'r') as g:\n","        old_list = json.load(g)\n","        for dic in total_list:\n","            if dic not in old_list:\n","                old_list.append(dic)\n","    json.dump(old_list, f, ensure_ascii=False, indent=4)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["# Delete & Rename"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["if os.path.exists('nhk.json') and os.path.exists('nhk_new.json'):\n","    os.remove('nhk.json')\n","    os.rename('nhk_new.json', 'nhk.json')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import pythainlp"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import json\n","with open('nhk.json') as f:\n","    data = json.load(f)\n","new = []\n","for k,v in data.items():\n","    v['id'] = k\n","    new.append(v)\n","\n","with open('nhk2.json', 'w') as f:\n","    json.dump(new, f, indent=4, ensure_ascii=False)   "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}